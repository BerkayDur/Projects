{"cells":[{"cell_type":"markdown","metadata":{"id":"pWgujXmGqzIC"},"source":["# Lab 6 - Aspect-Based Sentiment Analysis with BERT"]},{"cell_type":"markdown","metadata":{"id":"pr5PWYKGPi6R"},"source":["In this lab we turn a pre-trained BERT model into a trainable Keras layer and apply it to the Aspect-Based Sentiment Analysis (ABSA). You can find the task description from (https://aclanthology.org/D19-1654.pdf).\n","This task provides a review text dataset with aspects.\n","Given a review and an aspect, we need to classify the sentiment conveyed towards this aspect on a three-point scale: POSITIVE, NEUTRAL or NEGATIVE.\n","This is a multi-class classification task.\n","\n","BERT (Bidirectional Embedding Representations from Transformers) is a new model for pre-training language representations that obtains state-of-the-art results on many NLP tasks. We demonstrate how to integrate BERT as a custom Keras layer using the Huggingface library. \n","\n","In this lab, you will learn: \n","\n","1) How to use the Huggingface library.\n","\n","2) How to integrate BERT in the models built previously. \n","\n","3) How to use the TPU from Colab. **Note**: Running BERT on the CPU will be very slow. Thus we recommend you to do this lab on a Colab TPU provided by Google."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4spJ5PRhGJ1l"},"outputs":[],"source":["import keras\n","import numpy as np\n","from keras.layers import Lambda, GlobalAveragePooling1D, Dense, Embedding\n","from keras import backend as K\n","from keras.models import Sequential\n","import matplotlib.pyplot as plt\n","\n","from keras.layers import LSTM, RNN, Dropout, Input, LeakyReLU, Bidirectional,Conv1D, GlobalMaxPooling1D\n","from keras.layers.core import Dense\n","from keras.models import Model\n"]},{"cell_type":"markdown","metadata":{"id":"2oimYsLssuSs"},"source":["We first need to install the Huggingface's Transformers package. You can find the relevant doc from [here](https://huggingface.co/transformers/index.html)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AElpzsKFiZSo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678284546153,"user_tz":0,"elapsed":31891,"user":{"displayName":"Berkay Dur","userId":"09848658077603662329"}},"outputId":"331bdeb9-3bb2-4cdd-c3b7-bfe3f467e308"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.24.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n"]}],"source":["pip install transformers"]},{"cell_type":"markdown","metadata":{"id":"ebbamBD0xu5z"},"source":["## Preprocessing and Tokenization"]},{"cell_type":"markdown","metadata":{"id":"RbAMXQwqyVT8"},"source":["In this lab we will use DistilBERT (https://arxiv.org/pdf/1910.01108.pdf) instead of BERT: DistilBERT is a smaller and faster Transformer model trained via distilling BERT. It has 40% less parameters than the bert-base-uncased model. It runs 60% faster, while preserving 97% of BERT’s performance as measured on the GLUE language understanding benchmark.\n","\n","It is easy to switch between DistilBERT and BERT using the Huggingface transformers package. This package provides many pre-trained and pre-built models that are easy to use via a few lines of code."]},{"cell_type":"markdown","metadata":{"id":"V-cUTxt02dQb"},"source":["Before using DistilBERT or BERT, we need a tokenizer. Generally speaking, every BERT related model has its own tokenizer, trained for this particular model. \n","We can get the DistilBERT tokenizer from the **DistilBertTokenizer.from_pretrained** method."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hKj6Y_TydjeS","colab":{"base_uri":"https://localhost:8080/","height":197,"referenced_widgets":["6eef3784ce17466986276c89fe960d3a","01469a7523a442be82a3807be6935a8c","bf711d86fcd845d2b8ce42fb79d0b301","decc6b9c1c07426ab0d9e97689fcc8dd","d9df9b904212458683b1b1d62092a0a5","18fdbd69b9da448b91813d6d23b92796","fbdc3559428c4ba2bfca35e31cef12bc","85c95e92e0b140559ce47932e8887753","e2621e9976a94c4481f6acc699b203c8","3abfb68d82e7405db289e22e43d7a387","7b06f55097074229898887ba862e9224","226ea1c1cd654211b38a6cb766966462","29b423a607fc485fb6d9708f3b0fc6fb","c95be7f867b64db58c998fa0ea258ba6","af96571e0f6741fc81f2994a7eebae14","16e24cc6356240ba9466a67374744510","3b6363c5c5f541b8a42cacd01d7d66f5","feff43506ea14b3babda02c376bd3f74","7a0010a4b29c4f58b34c782ab194a647","bd05dcc7eb8644d3b91349cc95352b9b","6d6a20c6f5034ece840b4f7856b44055","354a9204335d4231bbc51980536618fa","8bd82db61d654b9cbca77ad2959c0a69","f54e9f31b2a0464c9b415ab2ae2516cd","fa080e6f893e49d1bbc3934d70fef239","b6b2d5149bdc4d1c92cacce73d1bb46b","a512238cab884809b480fe0fc636c0c8","57babcf64b6c44b6b66dd61aa4239178","df2677d68e0c4c98a2049b9be79a5240","0dff6ddef0bc4ce7a7a305754a115621","37a684a8e3ef45438635c8e2bc5820c2","57af8e105f67404a81316bf3234c1645","1af015cb121243bd99102ad2bdfe856c"]},"executionInfo":{"status":"ok","timestamp":1678284548070,"user_tz":0,"elapsed":1925,"user":{"displayName":"Berkay Dur","userId":"09848658077603662329"}},"outputId":"53e2cd9e-22b0-416b-987f-835ad3eb2549"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6eef3784ce17466986276c89fe960d3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"226ea1c1cd654211b38a6cb766966462"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bd82db61d654b9cbca77ad2959c0a69"}},"metadata":{}}],"source":["from transformers import DistilBertTokenizer, RobertaTokenizer \n","import tqdm\n","distil_bert = 'distilbert-base-uncased' # Pick a pre-trained model\n","\n","# Defining DistilBERT tokenizer\n","tokenizer = DistilBertTokenizer.from_pretrained(distil_bert, do_lower_case=True, add_special_tokens=True,\n","                                                max_length=128, pad_to_max_length=True)\n","\n","def tokenize(sentences, tokenizer, pad_length=128, pad_to_max_length=True ):\n","    if type(sentences) == str:\n","        inputs = tokenizer.encode_plus(sentences, add_special_tokens=True, max_length=pad_length, pad_to_max_length=pad_to_max_length, \n","                                             return_attention_mask=True, return_token_type_ids=True)\n","        return np.asarray(inputs['input_ids'], dtype='int32'), np.asarray(inputs['attention_mask'], dtype='int32'), np.asarray(inputs['token_type_ids'], dtype='int32')\n","    \n","    input_ids, input_masks, input_segments = [],[],[]\n","    for sentence in sentences:\n","        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=pad_length, pad_to_max_length=pad_to_max_length, \n","                                             return_attention_mask=True, return_token_type_ids=True)\n","        input_ids.append(inputs['input_ids'])\n","        input_masks.append(inputs['attention_mask'])\n","        input_segments.append(inputs['token_type_ids'])        \n","        \n","    return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32'), np.asarray(input_segments, dtype='int32')\n"]},{"cell_type":"markdown","metadata":{"id":"sqMo6CPS3qJZ"},"source":["Then we can use this tokenizer to tokenize our data. When working with word2vec and GloVe, we tokenized sentences into words ourselves and then converted the tokens into GloVe indices. But in BERT, we must use the BERT tokenizer that uses sub-word tokens.\n","\n","For example, for the sentence: **This is a pretrained model.** our previous word-based tokenizer will generate the following tokens:\n","\n","**\"this\", \"is\", \"a\", \"pretrained\", \"model\", \".\"**\n","\n","Then you will find out that the token \"pretrained\" is not in the GloVe word dictionary. Thus we can not assign it a trained word vector.\n","\n","The BERT tokenizer will separate the word \"pretrained\" into three sub-word tokens:\n","\n","**'pre', '##train', '##ed'**\n","\n","BERT thus uses these three token vectors to represent the word \"pretrained\". You will also see that the BERT tokenizer adds the special [CLS] token and the sentence separator [SEP] token."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iRoKe2DKyi41","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678284548070,"user_tz":0,"elapsed":14,"user":{"displayName":"Berkay Dur","userId":"09848658077603662329"}},"outputId":"71999a7d-6e75-4126-d946-8acc63f24acd"},"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["['the', 'capital', 'of', 'france', 'is', '[MASK]', '.'] \n","\n","['this', 'is', 'a', 'pre', '##train', '##ed', 'model', '.'] \n","\n","[ 101 1996 3007 1997 2605 2003  103 1012  102    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0]\n","[1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","['[CLS]', 'the', 'capital', 'of', 'france', 'is', '[MASK]', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'] \n","\n","[ 101 1996 3007 1997 2605 2003  103 1012  102]\n","[1 1 1 1 1 1 1 1 1]\n","['[CLS]', 'the', 'capital', 'of', 'france', 'is', '[MASK]', '.', '[SEP]'] \n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}],"source":["inputs = tokenizer.tokenize(\"The capital of France is [MASK].\")\n","print(inputs,'\\n')\n","\n","inputs = tokenizer.tokenize(\"This is a pretrained model.\")\n","print(inputs,'\\n')\n","\n","ids,masks,segments = tokenize(\"The capital of France is [MASK].\", tokenizer)\n","print(ids)\n","print(masks)\n","print(tokenizer.convert_ids_to_tokens(ids),\"\\n\")\n","\n","ids,masks,segments = tokenize(\"The capital of France is [MASK].\", tokenizer, pad_to_max_length=False)\n","print(ids)\n","print(masks)\n","print(tokenizer.convert_ids_to_tokens(ids),\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"J6OuZAA8sbdg"},"source":["## Loading Data"]},{"cell_type":"markdown","metadata":{"id":"cqvPQvgvPv1W"},"source":["### Downloading and preprocessing data"]},{"cell_type":"markdown","metadata":{"id":"EundMtGPpCdf"},"source":["Unlike the IMDB dataset that is included and preprocessed by Keras, the dataset we will be using is the aspect-based sentiment analysis (ABSA)  dataset, which consists of 5,297 labeled reviews. These are split into 4,297 reviews for training and 500 reviews for testing and validation, respectively. \n","\n","For ABSA, sentiment polarities were assigned with respect to the aspect terms.  The start and end positions for each aspect term are provided.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NyuSzkafqNca","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678284549532,"user_tz":0,"elapsed":1471,"user":{"displayName":"Berkay Dur","userId":"09848658077603662329"}},"outputId":"1158bd50-77b6-4309-a177-cc44034cc06a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training entries: 11186\n","Test entries: 1336\n"]}],"source":["import requests\n","def downloadfile(url):\n","  rq = requests.get(url)\n","  open(url.split('/')[-1], 'wb').write(rq.content)\n","downloadfile('https://raw.githubusercontent.com/siat-nlp/MAMS-for-ABSA/master/data/MAMS-ATSA/raw/train.xml')\n","downloadfile('https://raw.githubusercontent.com/siat-nlp/MAMS-for-ABSA/master/data/MAMS-ATSA/raw/val.xml')\n","downloadfile('https://raw.githubusercontent.com/siat-nlp/MAMS-for-ABSA/master/data/MAMS-ATSA/raw/test.xml')\n","\n","\n","# The code is modified from https://raw.githubusercontent.com/siat-nlp/MAMS-for-ABSA/master/data_process/utils.py\n","from xml.etree.ElementTree import parse\n","\n","def parse_sentence_term(path, lowercase=False):\n","    tree = parse(path)\n","    sentences = tree.getroot()\n","    data = []\n","    split_char = '__split__'\n","    for sentence in sentences:\n","        text = sentence.find('text')\n","        if text is None:\n","            continue\n","        text = text.text\n","        if lowercase:\n","            text = text.lower()\n","        aspectTerms = sentence.find('aspectTerms')\n","        if aspectTerms is None:\n","            continue\n","        for aspectTerm in aspectTerms:\n","            term = aspectTerm.get('term')\n","            if lowercase:\n","                term = term.lower()\n","            polarity = aspectTerm.get('polarity')\n","            start = aspectTerm.get('from')\n","            end = aspectTerm.get('to')\n","            piece = [text , term,  polarity , start , end]\n","            data.append(piece)\n","    return data\n","train = parse_sentence_term(\"train.xml\",True)\n","dev = parse_sentence_term(\"val.xml\",True)\n","test = parse_sentence_term(\"test.xml\",True)\n","\n","print(\"Training entries: {}\".format(len(train)))\n","print(\"Test entries: {}\".format(len(test)))\n"]},{"cell_type":"markdown","metadata":{"id":"6U4iCV9-rmay"},"source":["Let’s first see some examples from the data:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h-gjWRAuqg5s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678284549533,"user_tz":0,"elapsed":10,"user":{"displayName":"Berkay Dur","userId":"09848658077603662329"}},"outputId":"24ce03df-2d63-416d-a19a-935597516a08"},"outputs":[{"output_type":"stream","name":"stdout","text":["SENTENCE \t ASPECT \t LABEL \t ASPECT-START-INDEX \t ASPECT-END-INDEX\n","['the decor is not special at all but their food and amazing prices make up for it.', 'decor', 'negative', '4', '9']\n","['the decor is not special at all but their food and amazing prices make up for it.', 'food', 'positive', '42', '46']\n","['the decor is not special at all but their food and amazing prices make up for it.', 'prices', 'positive', '59', '65']\n","['when tables opened up, the manager sat another party before us.', 'tables', 'neutral', '5', '11']\n","['when tables opened up, the manager sat another party before us.', 'manager', 'negative', '27', '34']\n"]}],"source":["print(\"SENTENCE \\t ASPECT \\t LABEL \\t ASPECT-START-INDEX \\t ASPECT-END-INDEX\")\n","print(train[0])\n","print(train[1])\n","print(train[2])\n","print(train[3])\n","print(train[4])"]},{"cell_type":"code","source":["train_review = [i[0] for i in train]\n","train_aspect = [i[1] for i in train]\n","\n","dev_review = [i[0] for i in dev]\n","dev_aspect = [i[1] for i in dev]\n","\n","test_review = [i[0] for i in test]\n","test_aspect = [i[1] for i in test]"],"metadata":{"id":"Hz47kn95PF6_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tvuu4KhStqei"},"source":["Using the BERT `tokenize` function above, we can text and aspect words to integers:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gMCH1OoDrSNR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678284584553,"user_tz":0,"elapsed":35027,"user":{"displayName":"Berkay Dur","userId":"09848658077603662329"}},"outputId":"381ac8fd-400a-4da1-9c3c-6cd1e4d99792"},"outputs":[{"output_type":"stream","name":"stdout","text":["x_dev_aspect_int[0]:\n","[ 101 8974  102    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0]\n","x_dev_aspect_masks[0]:\n","[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","x_dev_review_int[0]:\n","[  101  2044  1037  3232  1997  8974  1010  1996 18726  1011  1011  1045\n","  2066  1996 27940  1013 24792  2621  4897  1998  1996 13675 11514  6508\n"," 26852  1011  1011  2175  2091  2307  1012   102     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0]\n","x_dev_review_masks[0]:\n","[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"]}],"source":["# Please write your code to generate the following data\n","\n","# x_train_review_int\n","# x_train_review_masks\n","# x_train_aspect_int\n","# x_train_aspect_masks\n","\n","# x_dev_review_int\n","# x_dev_review_masks\n","# x_dev_aspect_int\n","# x_dev_aspect_masks\n","\n","# x_test_review_int\n","# x_test_review_masks\n","# x_test_aspect_int\n","# x_test_aspect_masks\n","\n","# your code goes here\n","x_train_review_int, x_train_review_masks, _= tokenize(train_review, tokenizer)\n","x_train_aspect_int, x_train_aspect_masks, _= tokenize(train_aspect, tokenizer)\n","\n","x_dev_review_int, x_dev_review_masks, _= tokenize(dev_review, tokenizer)\n","x_dev_aspect_int, x_dev_aspect_masks, _= tokenize(dev_aspect, tokenizer)\n","\n","x_test_review_int, x_test_review_masks, _= tokenize(test_review, tokenizer)\n","x_test_aspect_int, x_test_aspect_masks, _= tokenize(test_aspect, tokenizer)\n","\n","\n","# You can check the results as follows:\n","assert len(x_train_aspect_int) == len(train)\n","assert len(x_train_aspect_masks) == len(x_train_aspect_int)\n","assert len(x_test_aspect_int) == len(test)\n","assert len(x_test_aspect_masks) == len(x_test_aspect_int)\n","print(\"x_dev_aspect_int[0]:\")\n","print(x_dev_aspect_int[0])\n","print(\"x_dev_aspect_masks[0]:\")\n","print(x_dev_aspect_masks[0])\n","print(\"x_dev_review_int[0]:\")\n","print(x_dev_review_int[0])\n","print(\"x_dev_review_masks[0]:\")\n","print(x_dev_review_masks[0])"]},{"cell_type":"markdown","metadata":{"id":"5IreFXgruZot"},"source":["We one-hot encode the labels, using 4 (Binary:100) to represent \"positive\", 2 (Binary:010) for \"neutral\", and 1 (Binary:001) for \"negative\"."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"abIb7Fe5u3GQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678284584838,"user_tz":0,"elapsed":299,"user":{"displayName":"Berkay Dur","userId":"09848658077603662329"}},"outputId":"713f7cf0-b1f3-465d-bf0a-c7f117b946a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0 0 1]\n","[1 0 0]\n","[1 0 0]\n","[0 1 0]\n","[0 0 1]\n"]}],"source":["def label2int(dataset):\n","  y = []\n","  for example in dataset:\n","    if example[2].lower() == \"negative\":\n","      y.append([0,0,1])\n","    elif example[2].lower() == \"neutral\":\n","      y.append([0,1,0])\n","    else:\n","      # assert example[2].lower() == \"positive\"\n","      y.append([1,0,0])\n","  return y\n","  \n","y_train = label2int(train)\n","y_dev = label2int(dev)\n","y_test = label2int(test)\n","y_train = np.array(y_train)\n","y_dev = np.array(y_dev)\n","y_test = np.array(y_test)\n","\n","print(y_train[0])\n","print(y_train[1])\n","print(y_train[2])\n","print(y_train[3])\n","print(y_train[4])"]},{"cell_type":"markdown","metadata":{"id":"9TnnSuspvC5b"},"source":["Now we have almost finished the data preprocessing. Unlike in the previous labs, there are two model inputs: review and aspect. The easiest way is to combine the review and aspect into one sentence and then input it into the model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nKOiVVXQu-_I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678284601784,"user_tz":0,"elapsed":16950,"user":{"displayName":"Berkay Dur","userId":"09848658077603662329"}},"outputId":"960c6136-f382-43f5-9e32-de90922481dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["[  101  2044  1037  3232  1997  8974  1010  1996 18726  1011  1011  1045\n","  2066  1996 27940  1013 24792  2621  4897  1998  1996 13675 11514  6508\n"," 26852  1011  1011  2175  2091  2307  1012   102  8974   102     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0]\n","[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] \n","\n","[  101  2044  1037  3232  1997  8974  1010  1996 18726  1011  1011  1045\n","  2066  1996 27940  1013 24792  2621  4897  1998  1996 13675 11514  6508\n"," 26852  1011  1011  2175  2091  2307  1012   102  8974   102     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0]\n","[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"]}],"source":["# Please write your code to combine sentences and aspect words into the following varibles\n","\n","# x_train_int\n","# x_train_masks\n","# x_dev_int\n","# x_dev_masks\n","# x_test_int\n","# x_test_masks\n","\n","# Tips: \n","# 1) Use the special token <SEP> to concatenate sentences and aspect words\n","# 2) Make sure they are paded/truncated to a max length\n","\n","# your code goes here\n","\n","x_train_int, x_train_masks, _ = tokenize([train[i][0] + \" [SEP] \" + train[i][1] for i in range(len(train))], tokenizer)\n","x_dev_int, x_dev_masks, _ = tokenize([dev[i][0] + \" [SEP] \" + dev[i][1] for i in range(len(dev))], tokenizer)\n","x_test_int, x_test_masks, _ = tokenize([test[i][0] + \" [SEP] \" + test[i][1] for i in range(len(test))], tokenizer)\n","\n","# Don't forget the to use the np.array function to wrap the outputs\n","x_train_int_np = np.array(x_train_int)\n","x_train_masks_np = np.array(x_train_masks)\n","x_dev_int_np = np.array(x_dev_int)\n","x_dev_masks_np = np.array(x_dev_masks)\n","x_test_int_np = np.array(x_test_int)\n","x_test_masks_np = np.array(x_test_masks)\n","\n","\n","print(x_dev_int[0])\n","print(x_dev_masks[0],'\\n')\n","print(x_dev_int_np[0])\n","print(x_dev_masks_np[0]) # sentence + aspect\n"]},{"cell_type":"code","source":["print(tokenize(train_review[0] + \"[SEP]\" + train_aspect[0], tokenizer))\n","print(train_review[0] + \" [SEP] \" + train_aspect[0])\n","print(tokenize(train_review[0],tokenizer))"],"metadata":{"id":"UajEv0awQtd5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678284601784,"user_tz":0,"elapsed":8,"user":{"displayName":"Berkay Dur","userId":"09848658077603662329"}},"outputId":"66682a35-f588-470e-e7ea-624d658feba6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(array([  101,  1996, 25545,  2003,  2025,  2569,  2012,  2035,  2021,\n","        2037,  2833,  1998,  6429,  7597,  2191,  2039,  2005,  2009,\n","        1012,   102, 25545,   102,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0], dtype=int32), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))\n","the decor is not special at all but their food and amazing prices make up for it. [SEP] decor\n","(array([  101,  1996, 25545,  2003,  2025,  2569,  2012,  2035,  2021,\n","        2037,  2833,  1998,  6429,  7597,  2191,  2039,  2005,  2009,\n","        1012,   102,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0], dtype=int32), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))\n"]}]},{"cell_type":"markdown","metadata":{"id":"UqvUGIwwGJqu"},"source":["## Model 1: Prebuilt Sequence Classification\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hSxC41ln07im"},"source":["The Huggingface transformer package provides many prebuilt models. Now let us try a sequence classification model based on DistilBERT. \n","\n","The models with BERT are much bigger than our previous models. To run it faster, we can use TPU. Detailed guidelines on how to use TPU can be found from https://www.tensorflow.org/guide/tpu."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1gXFbb2cxBlw","colab":{"base_uri":"https://localhost:8080/","height":236,"referenced_widgets":["1fea23684f17426d8299e1e144f9ccfa","6e392f6ac3b949ccb2415ef16eb7b7a5","6b121e303c6b41e2abe949174e61ceaf","a8590f7ce71e4d70acfef4fcb38738b3","cdb6be37b8d94db58d8330b6cb3f6670","d833f6d5b1d74fe09f1860d4951ecf71","6893bfdba40e48ab8fb479bc6e388f0d","0c175d7efbc84cd498e23eae53e9ecb7","d63c684833ac4b09aa684f187d8fdc0d","820ca9f9971e42aa98da939a094e9921","93ca2540479b4e859f5b9ce1719908df"]},"executionInfo":{"status":"ok","timestamp":1678284656898,"user_tz":0,"elapsed":55119,"user":{"displayName":"Berkay Dur","userId":"09848658077603662329"}},"outputId":"1ab5e27a-165a-4f1e-9727-7b408249b889"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)\"tf_model.h5\";:   0%|          | 0.00/363M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fea23684f17426d8299e1e144f9ccfa"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'vocab_projector', 'vocab_layer_norm', 'activation_13']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'classifier', 'dropout_19']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n","Instructions for updating:\n","Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"]}],"source":["from transformers import TFDistilBertForSequenceClassification, DistilBertConfig\n","import tensorflow as tf\n","\n","distil_bert = 'distilbert-base-uncased'\n","\n","config = DistilBertConfig(num_labels=3)\n","config.output_hidden_states = False\n","\n","def create_TFDistilBertForSequenceClassification():\n","  transformer_model = TFDistilBertForSequenceClassification.from_pretrained(distil_bert, config = config)\n","  input_ids = tf.keras.layers.Input(shape=(128,), name='input_token', dtype='int32')\n","  input_masks_ids = tf.keras.layers.Input(shape=(128,), name='masked_token', dtype='int32')\n","  X = transformer_model(input_ids, input_masks_ids)\n","  return tf.keras.Model(inputs=[input_ids, input_masks_ids], outputs = X)\n","\n","use_tpu = True\n","if use_tpu:\n","  # Create distribution strategy\n","  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","  tf.config.experimental_connect_to_cluster(tpu)\n","  tf.tpu.experimental.initialize_tpu_system(tpu)\n","  strategy = tf.distribute.TPUStrategy(tpu)\n","\n","  # Create model on TPU:\n","  with strategy.scope():\n","    model = create_TFDistilBertForSequenceClassification()\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n","    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","else:\n","  model = create_TFDistilBertForSequenceClassification()\n","  model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2CPFj0CMx9mw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678284656901,"user_tz":0,"elapsed":37,"user":{"displayName":"Berkay Dur","userId":"09848658077603662329"}},"outputId":"c0b2eefe-661c-43df-b156-c8cda78dec67"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_token (InputLayer)       [(None, 128)]        0           []                               \n","                                                                                                  \n"," masked_token (InputLayer)      [(None, 128)]        0           []                               \n","                                                                                                  \n"," tf_distil_bert_for_sequence_cl  TFSequenceClassifie  66955779   ['input_token[0][0]',            \n"," assification (TFDistilBertForS  rOutput(loss=None,               'masked_token[0][0]']           \n"," equenceClassification)         logits=(None, 3),                                                 \n","                                 hidden_states=None                                               \n","                                , attentions=None)                                                \n","                                                                                                  \n","==================================================================================================\n","Total params: 66,955,779\n","Trainable params: 66,955,779\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zQQH5lE_33Vn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678284909427,"user_tz":0,"elapsed":252553,"user":{"displayName":"Berkay Dur","userId":"09848658077603662329"}},"outputId":"96754240-9d6d-498c-c1e0-88d7e905007e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","22/22 [==============================] - 104s 2s/step - loss: 0.7467 - accuracy: 0.4380 - val_loss: 0.5804 - val_accuracy: 0.4595\n","Epoch 2/30\n","22/22 [==============================] - 5s 229ms/step - loss: 0.5519 - accuracy: 0.5485 - val_loss: 0.4867 - val_accuracy: 0.6547\n","Epoch 3/30\n","22/22 [==============================] - 5s 232ms/step - loss: 0.4729 - accuracy: 0.6719 - val_loss: 0.4358 - val_accuracy: 0.7357\n","Epoch 4/30\n","22/22 [==============================] - 5s 234ms/step - loss: 0.4047 - accuracy: 0.7543 - val_loss: 0.4262 - val_accuracy: 0.7643\n","Epoch 5/30\n","22/22 [==============================] - 5s 228ms/step - loss: 0.3555 - accuracy: 0.7952 - val_loss: 0.3895 - val_accuracy: 0.7748\n","Epoch 6/30\n","22/22 [==============================] - 5s 227ms/step - loss: 0.3590 - accuracy: 0.8097 - val_loss: 0.4547 - val_accuracy: 0.7808\n","Epoch 7/30\n","22/22 [==============================] - 5s 233ms/step - loss: 0.2944 - accuracy: 0.8413 - val_loss: 0.5192 - val_accuracy: 0.7980\n","Epoch 8/30\n","22/22 [==============================] - 5s 228ms/step - loss: 0.2633 - accuracy: 0.8647 - val_loss: 0.3865 - val_accuracy: 0.7988\n","Epoch 9/30\n","22/22 [==============================] - 5s 226ms/step - loss: 0.2513 - accuracy: 0.8766 - val_loss: 0.5283 - val_accuracy: 0.8086\n","Epoch 10/30\n","22/22 [==============================] - 5s 238ms/step - loss: 0.2616 - accuracy: 0.8644 - val_loss: 0.4390 - val_accuracy: 0.7140\n","Epoch 11/30\n","22/22 [==============================] - 5s 227ms/step - loss: 0.3167 - accuracy: 0.8259 - val_loss: 0.6594 - val_accuracy: 0.7950\n","Epoch 12/30\n","22/22 [==============================] - 5s 227ms/step - loss: 0.2480 - accuracy: 0.8832 - val_loss: 0.4363 - val_accuracy: 0.7898\n","Epoch 13/30\n","22/22 [==============================] - 5s 242ms/step - loss: 0.1953 - accuracy: 0.9018 - val_loss: 0.6137 - val_accuracy: 0.7965\n","Epoch 14/30\n","22/22 [==============================] - 5s 227ms/step - loss: 0.3653 - accuracy: 0.7385 - val_loss: 0.4874 - val_accuracy: 0.7335\n","Epoch 15/30\n","22/22 [==============================] - 5s 226ms/step - loss: 0.3490 - accuracy: 0.8124 - val_loss: 0.5966 - val_accuracy: 0.7823\n","Epoch 16/30\n","22/22 [==============================] - 5s 230ms/step - loss: 0.2322 - accuracy: 0.8898 - val_loss: 0.5174 - val_accuracy: 0.8101\n","Epoch 17/30\n","22/22 [==============================] - 5s 226ms/step - loss: 0.1937 - accuracy: 0.9032 - val_loss: 0.6472 - val_accuracy: 0.8048\n","Epoch 18/30\n","22/22 [==============================] - 5s 237ms/step - loss: 0.1855 - accuracy: 0.9100 - val_loss: 0.6624 - val_accuracy: 0.8101\n","Epoch 19/30\n","22/22 [==============================] - 5s 228ms/step - loss: 0.2322 - accuracy: 0.8807 - val_loss: 0.5631 - val_accuracy: 0.7635\n","Epoch 20/30\n","22/22 [==============================] - 5s 227ms/step - loss: 0.2916 - accuracy: 0.8498 - val_loss: 0.4866 - val_accuracy: 0.7958\n","Epoch 21/30\n","22/22 [==============================] - 5s 233ms/step - loss: 0.1982 - accuracy: 0.9037 - val_loss: 0.8033 - val_accuracy: 0.7973\n","Epoch 22/30\n","22/22 [==============================] - 5s 227ms/step - loss: 0.2245 - accuracy: 0.8984 - val_loss: 0.6417 - val_accuracy: 0.7913\n","Epoch 23/30\n","22/22 [==============================] - 5s 226ms/step - loss: 0.1751 - accuracy: 0.9189 - val_loss: 0.7375 - val_accuracy: 0.8011\n","Epoch 24/30\n","22/22 [==============================] - 5s 237ms/step - loss: 0.1637 - accuracy: 0.9237 - val_loss: 0.6860 - val_accuracy: 0.8056\n","Epoch 25/30\n","22/22 [==============================] - 5s 227ms/step - loss: 0.1271 - accuracy: 0.9401 - val_loss: 0.8223 - val_accuracy: 0.7980\n","Epoch 26/30\n","22/22 [==============================] - 5s 227ms/step - loss: 0.1354 - accuracy: 0.9435 - val_loss: 0.6936 - val_accuracy: 0.8026\n","Epoch 27/30\n","22/22 [==============================] - 5s 236ms/step - loss: 0.1372 - accuracy: 0.9389 - val_loss: 0.7502 - val_accuracy: 0.7988\n","Epoch 28/30\n","22/22 [==============================] - 5s 227ms/step - loss: 0.1105 - accuracy: 0.9511 - val_loss: 0.9954 - val_accuracy: 0.8048\n","Epoch 29/30\n","22/22 [==============================] - 5s 228ms/step - loss: 0.0933 - accuracy: 0.9620 - val_loss: 1.0965 - val_accuracy: 0.8093\n","Epoch 30/30\n","22/22 [==============================] - 5s 229ms/step - loss: 0.0958 - accuracy: 0.9659 - val_loss: 1.0940 - val_accuracy: 0.8108\n"]}],"source":["history = model.fit([x_train_int_np,x_train_masks_np],\n","                    y_train,\n","                    epochs=30,\n","                    batch_size=512,\n","                    validation_data=([x_dev_int_np,x_dev_masks_np], y_dev),\n","                    verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lQcytuBdaWVp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678284916287,"user_tz":0,"elapsed":6884,"user":{"displayName":"Berkay Dur","userId":"09848658077603662329"}},"outputId":"83ca59cc-10f1-4c16-ee14-30a03e826f9a"},"outputs":[{"output_type":"stream","name":"stdout","text":["42/42 [==============================] - 7s 91ms/step - loss: 1.0286 - accuracy: 0.8174\n","[1.0286388397216797, 0.817365288734436]\n"]}],"source":["results = model.evaluate([x_test_int_np,x_test_masks_np], y_test)\n","print(results)"]},{"cell_type":"markdown","metadata":{"id":"vdZ4nl08vp9A"},"source":["\n","## Model 2: Neural bag of words using BERT"]},{"cell_type":"markdown","metadata":{"id":"2gyCwXFj_R5w"},"source":["Here we will use model2 from Lab3 with BERT instead of the previous static word embeddings."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DStlnRQRf-4v"},"outputs":[],"source":["class GlobalAveragePooling1DMasked(GlobalAveragePooling1D):\n","    def call(self, x, mask=None):\n","        if mask != None:\n","            return K.sum(x, axis=1) / K.sum(mask, axis=1)\n","        else:\n","            return super().call(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8fTwmYDvNEyT"},"outputs":[],"source":["from transformers import TFDistilBertModel, DistilBertConfig\n","\n","def get_BERT_layer():\n","  distil_bert = 'distilbert-base-uncased'\n","  config = DistilBertConfig(dropout=0.2, attention_dropout=0.2)\n","  config.output_hidden_states = False\n","  return TFDistilBertModel.from_pretrained(distil_bert, config = config)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VICS9rY8C7KH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678284958800,"user_tz":0,"elapsed":42517,"user":{"displayName":"Berkay Dur","userId":"09848658077603662329"}},"outputId":"2909fb33-c83d-4193-94a5-f14b6287f468"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:TPU system grpc://10.45.199.210:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n","Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_projector', 'vocab_layer_norm', 'activation_13']\n","- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]}],"source":["import tensorflow as tf\n","hdepth=16\n","MAX_SEQUENCE_LENGTH = 128\n","EMBED_SIZE=100\n","\n","\n","def create_bag_of_words_BERT():\n","  # your code goes here\n","  bert_layer = get_BERT_layer()\n","\n","\n","  input_ids_in = Input((128,), dtype=\"int32\")\n","  input_masks_in = Input((128,), dtype=\"int32\")\n","\n","  x3 = bert_layer(input_ids_in,input_masks_in)\n","  x4 = GlobalAveragePooling1DMasked()(x3[0])\n","  x5 = Dense(16)(x4)\n","  label = Dense(3, activation=\"softmax\")(x5)\n","\n","  # transformer_model = TFDistilBertForSequenceClassification.from_pretrained(distil_bert, config = config)\n","  # input_ids = tf.keras.layers.Input(shape=(128,), name='input_token', dtype='int32')\n","  # input_masks_ids = tf.keras.layers.Input(shape=(128,), name='masked_token', dtype='int32')\n","  # X = transformer_model(input_ids, input_masks_ids)\n","  # return tf.keras.Model(inputs=[input_ids, input_masks_ids], outputs = X)\n","\n","  \n","  return Model(inputs=[input_ids_in,input_masks_in], outputs=[label],name='Model2_BERT')\n","\n","use_tpu = True\n","if use_tpu:\n","  # Create distribution strategy\n","  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","  tf.config.experimental_connect_to_cluster(tpu)\n","  tf.tpu.experimental.initialize_tpu_system(tpu)\n","  strategy = tf.distribute.TPUStrategy(tpu)\n","\n","  # Create model\n","  with strategy.scope():\n","    model2 = create_bag_of_words_BERT()\n","    optimizer2 = tf.keras.optimizers.Adam(learning_rate=5e-5)\n","    model2.compile(optimizer=optimizer2, loss='binary_crossentropy', metrics=['accuracy'])\n","else:\n","  model2 = create_bag_of_words_BERT()\n","  model2.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])"]},{"cell_type":"code","source":["model2.summary() "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GebkoriE5daJ","executionInfo":{"status":"ok","timestamp":1678284958802,"user_tz":0,"elapsed":35,"user":{"displayName":"Berkay Dur","userId":"09848658077603662329"}},"outputId":"4ddae58e-af93-4574-c6ea-7977b25d03c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"Model2_BERT\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 128)]        0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 128)]        0           []                               \n","                                                                                                  \n"," tf_distil_bert_model (TFDistil  TFBaseModelOutput(l  66362880   ['input_1[0][0]',                \n"," BertModel)                     ast_hidden_state=(N               'input_2[0][0]']                \n","                                one, 128, 768),                                                   \n","                                 hidden_states=None                                               \n","                                , attentions=None)                                                \n","                                                                                                  \n"," global_average_pooling1d_maske  (None, 768)         0           ['tf_distil_bert_model[0][0]']   \n"," d (GlobalAveragePooling1DMaske                                                                   \n"," d)                                                                                               \n","                                                                                                  \n"," dense (Dense)                  (None, 16)           12304       ['global_average_pooling1d_masked\n","                                                                 [0][0]']                         \n","                                                                                                  \n"," dense_1 (Dense)                (None, 3)            51          ['dense[0][0]']                  \n","                                                                                                  \n","==================================================================================================\n","Total params: 66,375,235\n","Trainable params: 66,375,235\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S0SbsCsxF1zi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678285213135,"user_tz":0,"elapsed":254355,"user":{"displayName":"Berkay Dur","userId":"09848658077603662329"}},"outputId":"23028d2b-19fc-454a-8508-59bf141ecb78"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","22/22 [==============================] - 107s 2s/step - loss: 0.5720 - accuracy: 0.5217 - val_loss: 0.4834 - val_accuracy: 0.6456\n","Epoch 2/30\n","22/22 [==============================] - 5s 226ms/step - loss: 0.4313 - accuracy: 0.6854 - val_loss: 0.3587 - val_accuracy: 0.7583\n","Epoch 3/30\n","22/22 [==============================] - 5s 226ms/step - loss: 0.3263 - accuracy: 0.7845 - val_loss: 0.3159 - val_accuracy: 0.7988\n","Epoch 4/30\n","22/22 [==============================] - 5s 237ms/step - loss: 0.2612 - accuracy: 0.8351 - val_loss: 0.3107 - val_accuracy: 0.8131\n","Epoch 5/30\n","22/22 [==============================] - 5s 228ms/step - loss: 0.2159 - accuracy: 0.8687 - val_loss: 0.3124 - val_accuracy: 0.8191\n","Epoch 6/30\n","22/22 [==============================] - 5s 228ms/step - loss: 0.1726 - accuracy: 0.8989 - val_loss: 0.3294 - val_accuracy: 0.8168\n","Epoch 7/30\n","22/22 [==============================] - 5s 227ms/step - loss: 0.1403 - accuracy: 0.9169 - val_loss: 0.3785 - val_accuracy: 0.8116\n","Epoch 8/30\n","22/22 [==============================] - 5s 226ms/step - loss: 0.1083 - accuracy: 0.9401 - val_loss: 0.3971 - val_accuracy: 0.8108\n","Epoch 9/30\n","22/22 [==============================] - 5s 235ms/step - loss: 0.0832 - accuracy: 0.9567 - val_loss: 0.4389 - val_accuracy: 0.8176\n","Epoch 10/30\n","22/22 [==============================] - 5s 228ms/step - loss: 0.0701 - accuracy: 0.9636 - val_loss: 0.4602 - val_accuracy: 0.8288\n","Epoch 11/30\n","22/22 [==============================] - 5s 228ms/step - loss: 0.0587 - accuracy: 0.9695 - val_loss: 0.4903 - val_accuracy: 0.8131\n","Epoch 12/30\n","22/22 [==============================] - 5s 235ms/step - loss: 0.0458 - accuracy: 0.9767 - val_loss: 0.5372 - val_accuracy: 0.8153\n","Epoch 13/30\n","22/22 [==============================] - 5s 228ms/step - loss: 0.0423 - accuracy: 0.9785 - val_loss: 0.5501 - val_accuracy: 0.8168\n","Epoch 14/30\n","22/22 [==============================] - 5s 228ms/step - loss: 0.0348 - accuracy: 0.9827 - val_loss: 0.5645 - val_accuracy: 0.8243\n","Epoch 15/30\n","22/22 [==============================] - 5s 237ms/step - loss: 0.0301 - accuracy: 0.9852 - val_loss: 0.5613 - val_accuracy: 0.8191\n","Epoch 16/30\n","22/22 [==============================] - 5s 229ms/step - loss: 0.0301 - accuracy: 0.9849 - val_loss: 0.5795 - val_accuracy: 0.8221\n","Epoch 17/30\n","22/22 [==============================] - 5s 231ms/step - loss: 0.0255 - accuracy: 0.9882 - val_loss: 0.5967 - val_accuracy: 0.8221\n","Epoch 18/30\n","22/22 [==============================] - 5s 237ms/step - loss: 0.0199 - accuracy: 0.9899 - val_loss: 0.5885 - val_accuracy: 0.8221\n","Epoch 19/30\n","22/22 [==============================] - 5s 226ms/step - loss: 0.0213 - accuracy: 0.9896 - val_loss: 0.6250 - val_accuracy: 0.8146\n","Epoch 20/30\n","22/22 [==============================] - 5s 228ms/step - loss: 0.0185 - accuracy: 0.9920 - val_loss: 0.5999 - val_accuracy: 0.8258\n","Epoch 21/30\n","22/22 [==============================] - 5s 228ms/step - loss: 0.0160 - accuracy: 0.9921 - val_loss: 0.6664 - val_accuracy: 0.8198\n","Epoch 22/30\n","22/22 [==============================] - 5s 229ms/step - loss: 0.0141 - accuracy: 0.9936 - val_loss: 0.6714 - val_accuracy: 0.8273\n","Epoch 23/30\n","22/22 [==============================] - 5s 235ms/step - loss: 0.0141 - accuracy: 0.9932 - val_loss: 0.6684 - val_accuracy: 0.8326\n","Epoch 24/30\n","22/22 [==============================] - 5s 228ms/step - loss: 0.0177 - accuracy: 0.9916 - val_loss: 0.6236 - val_accuracy: 0.8288\n","Epoch 25/30\n","22/22 [==============================] - 5s 225ms/step - loss: 0.0159 - accuracy: 0.9922 - val_loss: 0.6736 - val_accuracy: 0.8243\n","Epoch 26/30\n","22/22 [==============================] - 5s 234ms/step - loss: 0.0135 - accuracy: 0.9943 - val_loss: 0.6421 - val_accuracy: 0.8303\n","Epoch 27/30\n","22/22 [==============================] - 5s 227ms/step - loss: 0.0102 - accuracy: 0.9954 - val_loss: 0.6887 - val_accuracy: 0.8288\n","Epoch 28/30\n","22/22 [==============================] - 5s 227ms/step - loss: 0.0108 - accuracy: 0.9944 - val_loss: 0.6449 - val_accuracy: 0.8311\n","Epoch 29/30\n","22/22 [==============================] - 5s 235ms/step - loss: 0.0099 - accuracy: 0.9955 - val_loss: 0.6798 - val_accuracy: 0.8191\n","Epoch 30/30\n","22/22 [==============================] - 5s 226ms/step - loss: 0.0106 - accuracy: 0.9948 - val_loss: 0.6687 - val_accuracy: 0.8303\n"]}],"source":["\n","history = model2.fit([x_train_int_np,x_train_masks_np],\n","                    y_train,\n","                    epochs=30,\n","                    batch_size=512,\n","                    validation_data=([x_dev_int_np,x_dev_masks_np], y_dev),\n","                    verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rs0_vvG6UQtv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678285221395,"user_tz":0,"elapsed":8277,"user":{"displayName":"Berkay Dur","userId":"09848658077603662329"}},"outputId":"e2bfdf36-89cf-4808-ecf8-ee508a5f0369"},"outputs":[{"output_type":"stream","name":"stdout","text":["42/42 [==============================] - 8s 93ms/step - loss: 0.6841 - accuracy: 0.8204\n","[0.6841117143630981, 0.8203592896461487]\n"]}],"source":["results = model2.evaluate([x_test_int_np,x_test_masks_np], y_test)\n","print(results)"]},{"cell_type":"markdown","metadata":{"id":"awOphcCnhEwv"},"source":["## Model 3: CNN or LSTM with BERT"]},{"cell_type":"markdown","source":[],"metadata":{"id":"pF3md5lwuoEJ"}},{"cell_type":"markdown","metadata":{"id":"E5codSzohQ_9"},"source":["Please follow the architecture for model2 to construct a CNN or an LSTM model on the top of BERT. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JMiiWhW4hPRA"},"outputs":[],"source":["# your code goes here\n","\n","\n","def create_model_3():\n","  BERT_layer = get_BERT_layer()\n"," \n","  x1 = Input((128,), dtype=\"int32\")\n","  x2 = Input((128,), dtype=\"int32\")\n","  x3 = BERT_layer(x1, x2)\n","  x4 = LSTM(100)(x3[0])\n","  x5 = Dense(3, activation=\"softmax\")(x4)\n","\n","  return Model(inputs=[x1,x2], outputs=[x5])"]},{"cell_type":"code","source":["use_tpu = True\n","if use_tpu:\n","  # Create distribution strategy\n","  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","  tf.config.experimental_connect_to_cluster(tpu)\n","  tf.tpu.experimental.initialize_tpu_system(tpu)\n","  strategy = tf.distribute.TPUStrategy(tpu)\n","\n","  # Create model\n","  with strategy.scope():\n","    model3 = create_model_3()\n","    optimizer3 = tf.keras.optimizers.Adam(learning_rate=5e-5)\n","    model3.compile(optimizer=optimizer3, loss='binary_crossentropy', metrics=['accuracy'])\n","else:\n","  model3 = create_model_3()\n","  model3.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eBg7OkhFfItU","executionInfo":{"status":"ok","timestamp":1678285274662,"user_tz":0,"elapsed":53284,"user":{"displayName":"Berkay Dur","userId":"09848658077603662329"}},"outputId":"3705b08c-4263-438c-961c-aaee4b467042"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:TPU system grpc://10.45.199.210:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n","Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_projector', 'vocab_layer_norm', 'activation_13']\n","- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]}]},{"cell_type":"code","source":["model3.summary() "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zcp7R1035ozX","executionInfo":{"status":"ok","timestamp":1678285274662,"user_tz":0,"elapsed":13,"user":{"displayName":"Berkay Dur","userId":"09848658077603662329"}},"outputId":"43304274-77ae-488a-a0fe-802e794b1b2a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_3 (InputLayer)           [(None, 128)]        0           []                               \n","                                                                                                  \n"," input_4 (InputLayer)           [(None, 128)]        0           []                               \n","                                                                                                  \n"," tf_distil_bert_model_1 (TFDist  TFBaseModelOutput(l  66362880   ['input_3[0][0]',                \n"," ilBertModel)                   ast_hidden_state=(N               'input_4[0][0]']                \n","                                one, 128, 768),                                                   \n","                                 hidden_states=None                                               \n","                                , attentions=None)                                                \n","                                                                                                  \n"," lstm (LSTM)                    (None, 100)          347600      ['tf_distil_bert_model_1[0][0]'] \n","                                                                                                  \n"," dense_2 (Dense)                (None, 3)            303         ['lstm[0][0]']                   \n","                                                                                                  \n","==================================================================================================\n","Total params: 66,710,783\n","Trainable params: 66,710,783\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c9HmJNzNpIEM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678285580021,"user_tz":0,"elapsed":305362,"user":{"displayName":"Berkay Dur","userId":"09848658077603662329"}},"outputId":"cdeb6451-5830-4afe-fb59-9cc62ac29a57"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","22/22 [==============================] - 115s 3s/step - loss: 0.5813 - accuracy: 0.4898 - val_loss: 0.4832 - val_accuracy: 0.6449\n","Epoch 2/30\n","22/22 [==============================] - 6s 295ms/step - loss: 0.4233 - accuracy: 0.7000 - val_loss: 0.3535 - val_accuracy: 0.7658\n","Epoch 3/30\n","22/22 [==============================] - 6s 293ms/step - loss: 0.3201 - accuracy: 0.7906 - val_loss: 0.3198 - val_accuracy: 0.7973\n","Epoch 4/30\n","22/22 [==============================] - 6s 295ms/step - loss: 0.2659 - accuracy: 0.8384 - val_loss: 0.3018 - val_accuracy: 0.8093\n","Epoch 5/30\n","22/22 [==============================] - 6s 294ms/step - loss: 0.2238 - accuracy: 0.8664 - val_loss: 0.3096 - val_accuracy: 0.8146\n","Epoch 6/30\n","22/22 [==============================] - 7s 303ms/step - loss: 0.1839 - accuracy: 0.8956 - val_loss: 0.3246 - val_accuracy: 0.8153\n","Epoch 7/30\n","22/22 [==============================] - 7s 297ms/step - loss: 0.1523 - accuracy: 0.9182 - val_loss: 0.3362 - val_accuracy: 0.8116\n","Epoch 8/30\n","22/22 [==============================] - 7s 304ms/step - loss: 0.1249 - accuracy: 0.9356 - val_loss: 0.3559 - val_accuracy: 0.8033\n","Epoch 9/30\n","22/22 [==============================] - 6s 292ms/step - loss: 0.1143 - accuracy: 0.9408 - val_loss: 0.3598 - val_accuracy: 0.8183\n","Epoch 10/30\n","22/22 [==============================] - 7s 302ms/step - loss: 0.0916 - accuracy: 0.9549 - val_loss: 0.3555 - val_accuracy: 0.8251\n","Epoch 11/30\n","22/22 [==============================] - 6s 293ms/step - loss: 0.0769 - accuracy: 0.9646 - val_loss: 0.3947 - val_accuracy: 0.8213\n","Epoch 12/30\n","22/22 [==============================] - 7s 300ms/step - loss: 0.0697 - accuracy: 0.9665 - val_loss: 0.3881 - val_accuracy: 0.8123\n","Epoch 13/30\n","22/22 [==============================] - 6s 295ms/step - loss: 0.0588 - accuracy: 0.9740 - val_loss: 0.4286 - val_accuracy: 0.8251\n","Epoch 14/30\n","22/22 [==============================] - 6s 295ms/step - loss: 0.0630 - accuracy: 0.9697 - val_loss: 0.4350 - val_accuracy: 0.8078\n","Epoch 15/30\n","22/22 [==============================] - 7s 298ms/step - loss: 0.0460 - accuracy: 0.9802 - val_loss: 0.4261 - val_accuracy: 0.8176\n","Epoch 16/30\n","22/22 [==============================] - 6s 296ms/step - loss: 0.0388 - accuracy: 0.9840 - val_loss: 0.4437 - val_accuracy: 0.8198\n","Epoch 17/30\n","22/22 [==============================] - 6s 295ms/step - loss: 0.0384 - accuracy: 0.9832 - val_loss: 0.4364 - val_accuracy: 0.8228\n","Epoch 18/30\n","22/22 [==============================] - 6s 294ms/step - loss: 0.0389 - accuracy: 0.9834 - val_loss: 0.4555 - val_accuracy: 0.8198\n","Epoch 19/30\n","22/22 [==============================] - 6s 294ms/step - loss: 0.0338 - accuracy: 0.9869 - val_loss: 0.4562 - val_accuracy: 0.8258\n","Epoch 20/30\n","22/22 [==============================] - 6s 292ms/step - loss: 0.0316 - accuracy: 0.9872 - val_loss: 0.4698 - val_accuracy: 0.8198\n","Epoch 21/30\n","22/22 [==============================] - 7s 301ms/step - loss: 0.0254 - accuracy: 0.9907 - val_loss: 0.4844 - val_accuracy: 0.8236\n","Epoch 22/30\n","22/22 [==============================] - 6s 293ms/step - loss: 0.0268 - accuracy: 0.9896 - val_loss: 0.4755 - val_accuracy: 0.8266\n","Epoch 23/30\n","22/22 [==============================] - 7s 299ms/step - loss: 0.0222 - accuracy: 0.9915 - val_loss: 0.4810 - val_accuracy: 0.8243\n","Epoch 24/30\n","22/22 [==============================] - 6s 291ms/step - loss: 0.0227 - accuracy: 0.9919 - val_loss: 0.5038 - val_accuracy: 0.8243\n","Epoch 25/30\n","22/22 [==============================] - 7s 298ms/step - loss: 0.0223 - accuracy: 0.9916 - val_loss: 0.4961 - val_accuracy: 0.8266\n","Epoch 26/30\n","22/22 [==============================] - 6s 290ms/step - loss: 0.0214 - accuracy: 0.9917 - val_loss: 0.4966 - val_accuracy: 0.8153\n","Epoch 27/30\n","22/22 [==============================] - 6s 296ms/step - loss: 0.0209 - accuracy: 0.9922 - val_loss: 0.4848 - val_accuracy: 0.8206\n","Epoch 28/30\n","22/22 [==============================] - 6s 292ms/step - loss: 0.0200 - accuracy: 0.9928 - val_loss: 0.5065 - val_accuracy: 0.8101\n","Epoch 29/30\n","22/22 [==============================] - 6s 291ms/step - loss: 0.0176 - accuracy: 0.9931 - val_loss: 0.5214 - val_accuracy: 0.8213\n","Epoch 30/30\n","22/22 [==============================] - 6s 290ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.5167 - val_accuracy: 0.8183\n"]}],"source":["\n","history = model3.fit([x_train_int_np,x_train_masks_np],\n","                    y_train,\n","                    epochs=30,\n","                    batch_size=512,\n","                    validation_data=([x_dev_int_np,x_dev_masks_np], y_dev),\n","                    verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W7TXLjQhpY--","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678285588547,"user_tz":0,"elapsed":8529,"user":{"displayName":"Berkay Dur","userId":"09848658077603662329"}},"outputId":"f34ef194-fe79-4d6a-f28a-5965fbccb1c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["42/42 [==============================] - 9s 110ms/step - loss: 0.4810 - accuracy: 0.8353\n","[0.4810287654399872, 0.8353293538093567]\n"]}],"source":["results = model3.evaluate([x_test_int_np,x_test_masks_np], y_test)\n","print(results)"]},{"cell_type":"code","source":[],"metadata":{"id":"hOrEWnT7eman"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":["UqvUGIwwGJqu","vdZ4nl08vp9A"],"provenance":[{"file_id":"1hzzPiNMoC4EUcAQ0bMzSwGiwlxZzQ5pJ","timestamp":1676798541489}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"6eef3784ce17466986276c89fe960d3a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_01469a7523a442be82a3807be6935a8c","IPY_MODEL_bf711d86fcd845d2b8ce42fb79d0b301","IPY_MODEL_decc6b9c1c07426ab0d9e97689fcc8dd"],"layout":"IPY_MODEL_d9df9b904212458683b1b1d62092a0a5"}},"01469a7523a442be82a3807be6935a8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18fdbd69b9da448b91813d6d23b92796","placeholder":"​","style":"IPY_MODEL_fbdc3559428c4ba2bfca35e31cef12bc","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"bf711d86fcd845d2b8ce42fb79d0b301":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_85c95e92e0b140559ce47932e8887753","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e2621e9976a94c4481f6acc699b203c8","value":231508}},"decc6b9c1c07426ab0d9e97689fcc8dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3abfb68d82e7405db289e22e43d7a387","placeholder":"​","style":"IPY_MODEL_7b06f55097074229898887ba862e9224","value":" 232k/232k [00:00&lt;00:00, 2.54MB/s]"}},"d9df9b904212458683b1b1d62092a0a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18fdbd69b9da448b91813d6d23b92796":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbdc3559428c4ba2bfca35e31cef12bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"85c95e92e0b140559ce47932e8887753":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2621e9976a94c4481f6acc699b203c8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3abfb68d82e7405db289e22e43d7a387":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b06f55097074229898887ba862e9224":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"226ea1c1cd654211b38a6cb766966462":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_29b423a607fc485fb6d9708f3b0fc6fb","IPY_MODEL_c95be7f867b64db58c998fa0ea258ba6","IPY_MODEL_af96571e0f6741fc81f2994a7eebae14"],"layout":"IPY_MODEL_16e24cc6356240ba9466a67374744510"}},"29b423a607fc485fb6d9708f3b0fc6fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b6363c5c5f541b8a42cacd01d7d66f5","placeholder":"​","style":"IPY_MODEL_feff43506ea14b3babda02c376bd3f74","value":"Downloading (…)okenizer_config.json: 100%"}},"c95be7f867b64db58c998fa0ea258ba6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a0010a4b29c4f58b34c782ab194a647","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd05dcc7eb8644d3b91349cc95352b9b","value":28}},"af96571e0f6741fc81f2994a7eebae14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d6a20c6f5034ece840b4f7856b44055","placeholder":"​","style":"IPY_MODEL_354a9204335d4231bbc51980536618fa","value":" 28.0/28.0 [00:00&lt;00:00, 821B/s]"}},"16e24cc6356240ba9466a67374744510":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b6363c5c5f541b8a42cacd01d7d66f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"feff43506ea14b3babda02c376bd3f74":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a0010a4b29c4f58b34c782ab194a647":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd05dcc7eb8644d3b91349cc95352b9b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6d6a20c6f5034ece840b4f7856b44055":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"354a9204335d4231bbc51980536618fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8bd82db61d654b9cbca77ad2959c0a69":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f54e9f31b2a0464c9b415ab2ae2516cd","IPY_MODEL_fa080e6f893e49d1bbc3934d70fef239","IPY_MODEL_b6b2d5149bdc4d1c92cacce73d1bb46b"],"layout":"IPY_MODEL_a512238cab884809b480fe0fc636c0c8"}},"f54e9f31b2a0464c9b415ab2ae2516cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57babcf64b6c44b6b66dd61aa4239178","placeholder":"​","style":"IPY_MODEL_df2677d68e0c4c98a2049b9be79a5240","value":"Downloading (…)lve/main/config.json: 100%"}},"fa080e6f893e49d1bbc3934d70fef239":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0dff6ddef0bc4ce7a7a305754a115621","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_37a684a8e3ef45438635c8e2bc5820c2","value":483}},"b6b2d5149bdc4d1c92cacce73d1bb46b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57af8e105f67404a81316bf3234c1645","placeholder":"​","style":"IPY_MODEL_1af015cb121243bd99102ad2bdfe856c","value":" 483/483 [00:00&lt;00:00, 15.9kB/s]"}},"a512238cab884809b480fe0fc636c0c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57babcf64b6c44b6b66dd61aa4239178":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df2677d68e0c4c98a2049b9be79a5240":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0dff6ddef0bc4ce7a7a305754a115621":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37a684a8e3ef45438635c8e2bc5820c2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"57af8e105f67404a81316bf3234c1645":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1af015cb121243bd99102ad2bdfe856c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1fea23684f17426d8299e1e144f9ccfa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6e392f6ac3b949ccb2415ef16eb7b7a5","IPY_MODEL_6b121e303c6b41e2abe949174e61ceaf","IPY_MODEL_a8590f7ce71e4d70acfef4fcb38738b3"],"layout":"IPY_MODEL_cdb6be37b8d94db58d8330b6cb3f6670"}},"6e392f6ac3b949ccb2415ef16eb7b7a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d833f6d5b1d74fe09f1860d4951ecf71","placeholder":"​","style":"IPY_MODEL_6893bfdba40e48ab8fb479bc6e388f0d","value":"Downloading (…)&quot;tf_model.h5&quot;;: 100%"}},"6b121e303c6b41e2abe949174e61ceaf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c175d7efbc84cd498e23eae53e9ecb7","max":363423424,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d63c684833ac4b09aa684f187d8fdc0d","value":363423424}},"a8590f7ce71e4d70acfef4fcb38738b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_820ca9f9971e42aa98da939a094e9921","placeholder":"​","style":"IPY_MODEL_93ca2540479b4e859f5b9ce1719908df","value":" 363M/363M [00:02&lt;00:00, 139MB/s]"}},"cdb6be37b8d94db58d8330b6cb3f6670":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d833f6d5b1d74fe09f1860d4951ecf71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6893bfdba40e48ab8fb479bc6e388f0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c175d7efbc84cd498e23eae53e9ecb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d63c684833ac4b09aa684f187d8fdc0d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"820ca9f9971e42aa98da939a094e9921":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93ca2540479b4e859f5b9ce1719908df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}