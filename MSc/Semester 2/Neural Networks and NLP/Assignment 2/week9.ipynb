{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"zjmcBKBxDmTI"},"source":["#**Lab 9 - Coreference Resolution**\n","\n","\n","March 21st\n","\n","\n","\n","In this lab, we are going to build a coreference system based on the mention-ranking algorithm proposed by Lee et al (2017).  You will get part of the code required to build the system, and you are required to fill three code blocks. Hints will be provided to guide you through. \n","\n","The first part of the notebook will show how to apply coreference resolution to English using a few examples. Then you have to apply that to a real dataset.  \n","\n","In total, you will be given two python files (*.py), three JSON files (*.jsonlines) and one embedding file (*.txt):\n","\n","*   **metric.py**: is used to compute the CoNLL scores; you don’t need to change it.\n","*   **[train/test/dev].jsonl** Documents are the training, testing and development set will be used for training and evaluating the model, which are ready to use. \n","*   **word_embeddings.filtered.txt** is pre-trained 300-dimensional FastText word embeddings. The original file is large, so we‘ve removed all the words that do not appear in the datasets to make it much smaller.\n","\n","These files are contained in the folder coreference_lab_files provided with the lab.\n"]},{"cell_type":"markdown","metadata":{"id":"_-hCv9PEH1xe"},"source":["##**0. Mount your google drive to google colab.**\n","\n","First, we will mount our google drive folders to Colab so we can access the filtered glove embeddings and the conll scorer. (Please upload them to your drive first.)\n","\n","To mount your drive, run the block of code below and complete the instructions as prompted"]},{"cell_type":"code","source":["from google.colab import drive, output\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XWTboQ-xWFY1","outputId":"c508d315-d678-4e1b-c2a5-aef45403f8c0","executionInfo":{"status":"ok","timestamp":1682160832956,"user_tz":-60,"elapsed":1985,"user":{"displayName":"Lydia Franklin","userId":"02300291642349467188"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"QzRk_pjoJX8s"},"source":["##**1. Add relevant paths**\n","\n","Next, we will append the path to the google drive folder containing the forementioned files to google colab.\n","\n"]},{"cell_type":"code","metadata":{"id":"sE7JjVsfKB7Y"},"source":["# IMPORTANT change this to the path to your folder. Remember to start from the home directory, 'My Drive'\n","# PATH_TO_FOLDER = \"/content/drive/MyDrive/Colab_uni/7001p_ass_2/week9/coref_files/\"\n","PATH_TO_FOLDER = \"/content/drive/MyDrive/7001p_ass_2/week9/coref_files/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mGgQCmpUJki_"},"source":["import sys\n","sys.path.append(PATH_TO_FOLDER)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rUADSXAKLoer"},"source":["Now we can also add the paths to our dev/test/train files and our filtered embeddings\n"]},{"cell_type":"code","metadata":{"id":"i9oagEtOLvLG"},"source":["DEV_PATH = PATH_TO_FOLDER + 'dev.jsonl'\n","TEST_PATH = PATH_TO_FOLDER + 'test.jsonl'\n","TRAIN_PATH = PATH_TO_FOLDER + 'train.jsonl'\n","\n","EMBEDDING_PATH = PATH_TO_FOLDER + 'word_embeddings.filtered.txt'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dOxJXF6rMZDO"},"source":["\n","##**2. Import files**\n","\n","We can now import metrics.py along with other python modules"]},{"cell_type":"code","metadata":{"id":"qK_q_BJVMYMz"},"source":["%%capture\n","\n","from keras import Input,Model\n","from keras import backend as K\n","from keras.layers import Dropout,Dense,LSTM,Bidirectional,Lambda,Reshape\n","import numpy as np\n","import tensorflow as tf \n","import random\n","import json,time,collections,random, metrics\n","\n","#seed everything\n","seed_value = 42\n","random.seed(seed_value)\n","np.random.seed(seed_value)\n","tf.random.set_seed(seed_value)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YFkp8bcxNq7U"},"source":["## **3. Creating an embedding dictionary**\n","\n","Using the embedding file, we will create an embedding dictionary,\n","for easy access while preparing our data"]},{"cell_type":"code","metadata":{"id":"CfFqHWl3Ot08"},"source":["# the dimension of the pretrained embeddings\n","EMBEDDING_SIZE = 300"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gpTTwvYCNplG"},"source":["def load_embeddings(embedding_path=EMBEDDING_PATH, embedding_size=EMBEDDING_SIZE):\n","    print(\"Loading word embeddings from {}...\".format(embedding_path))\n","    embeddings = collections.defaultdict(lambda: np.zeros(embedding_size))\n","    for line in open(embedding_path):\n","        splitter = line.find(' ')\n","        emb = np.fromstring(line[splitter + 1:], np.float32, sep=' ')\n","        assert len(emb) == embedding_size\n","        embeddings[line[:splitter]] = emb\n","    print(\"Finished loading word embeddings\")\n","    print(\"Number of words: \" + str(len(embeddings)))\n","    return embeddings"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CY7_Mc3bOyMh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fe1c8768-715b-4f71-ef07-926fba4ca9f4","executionInfo":{"status":"ok","timestamp":1682160843933,"user_tz":-60,"elapsed":879,"user":{"displayName":"Lydia Franklin","userId":"02300291642349467188"}}},"source":["EMBEDDING_DICT = load_embeddings() "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading word embeddings from /content/drive/MyDrive/7001p_ass_2/week9/coref_files/word_embeddings.filtered.txt...\n","Finished loading word embeddings\n","Number of words: 4675\n"]}]},{"cell_type":"markdown","metadata":{"id":"q4BgyGNrQnTy"},"source":["##**4. Preparing Documents for Coreference**"]},{"cell_type":"markdown","metadata":{"id":"1xqZA8TxQ2zR"},"source":["In this section,  we will show how to prepare the dataset for coreference resolution using a few examples in English. Then youwill have to prepare for the Arabic dataset in the jsonfiles.\n","<br>\n","\n","Each line in a given json file contains information for a single document. The “doc_key” stores the name of the document; the “sentences” points you to tokenized sentences of the document; the “clusters” element stores the coreference clusters. Each of the clusters contains a number of mentions encoded, each of the mentions has a start and an end indices, denoting the position of its first token and the index its last token within the document. \n","As an illustration, consider the dummy dataset in the block of code below containing one document. Run the code cell to see the clusters of coreferent mentions.\n"]},{"cell_type":"code","metadata":{"id":"IK_Clal1RL5g","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5f9b2740-0d9d-4e25-e112-124548d12b69","executionInfo":{"status":"ok","timestamp":1682160843934,"user_tz":-60,"elapsed":18,"user":{"displayName":"Lydia Franklin","userId":"02300291642349467188"}}},"source":["dummy_dataset = [{'doc_key': 'large_cat',\n","                  'sentences':[['The', 'large', 'cat', 'yawned', '.'],\n","                               ['He','was', 'very', 'hungry', 'as', 'he', 'had', 'not', 'eaten', 'since', 'breakfast','.'],\n","                               ['An', 'unfortunate', 'rat', 'came', 'along', '.'],\n","                               ['The', 'cat', 'gobbled', 'him', 'up', '.']],\n","                  'clusters': [[[0, 2], [5, 5], [10, 10], [23, 24]], [[17, 19], [26, 26]]]\n","                }]\n","\n","\n","sents = [w for sent in dummy_dataset[0]['sentences'] for w in sent]\n","print('These are the clusters in %s' %dummy_dataset[0]['doc_key'])\n","for cl_idx, cl in enumerate(dummy_dataset[0]['clusters']):\n","    print('Cluster ' + str(cl_idx) + ':', [' '.join(sents[s: e+1])  for s, e in cl])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["These are the clusters in large_cat\n","Cluster 0: ['The large cat', 'He', 'he', 'The cat']\n","Cluster 1: ['An unfortunate rat', 'him']\n"]}]},{"cell_type":"markdown","metadata":{"id":"VR0D0wOlYg_J"},"source":["To prepare the each dataset for the coreference resolution model, we will need to create variables from the each document:\n","\n","1.   Embedded Sentences: A 1 X num_sents X num_words X embedding size array for each document. \n","2.   Mention Pairs: A 1 X num_pairs X 4 array like so [anaphor_start, anaphor_end, antecedent_start, antecedent_end]\n","3. Mention Pair Labels: A num_pairs X 1 array containing corresponding labels for each mention pair (i.e. 1 if the pair of mentions are coreferent, 0 otherwise). \n","\n","The functions that follow in the subsections below contains code for extracting this dataset. Study them and test their functionality using the dummy dataset.\n","In section 4.4, you'll use these functions to create the dev, test and train datasets."]},{"cell_type":"markdown","metadata":{"id":"r1BX3m74VjT9"},"source":["###**4.1 Getting the mentions from the clusters**\n","\n","The following block of code gets the mentions from a given cluster in a document. "]},{"cell_type":"code","metadata":{"id":"uUxPZC5LThS8"},"source":["def get_mentions(clusters):\n","\n","    # get a list of mentions (as tuples) sorted by start indices.\n","    gold_mentions = sorted([tuple(m) for cl in clusters for m in cl])\n","\n","    # number of mentions\n","    num_mentions = len(gold_mentions)\n","\n","    # assign unique indices to each mention in the mention list based on its position in the list\n","    gold_mention_map = {m: i for i, m in enumerate(gold_mentions)}\n","\n","    # assign cluster ids to each mention in order E.g. cluser_ids = [4, 11, 5, 4, ..] => mention 0 is in cluster 4\n","    # along with mention 3.\n","    cluster_ids = [0]*num_mentions\n","    for cid, cluster in enumerate(clusters):\n","        for mention in cluster:\n","            cluster_ids[gold_mention_map[tuple(mention)]] = cid\n","\n","    return gold_mentions, gold_mention_map, cluster_ids, num_mentions\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MpCkYY8xWee6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8caceb88-68e6-49d8-875f-b063b46740c9","executionInfo":{"status":"ok","timestamp":1682160843935,"user_tz":-60,"elapsed":16,"user":{"displayName":"Lydia Franklin","userId":"02300291642349467188"}}},"source":["dmentions, dment_map, dcluster_ids, dnum_mentions = get_mentions(dummy_dataset[0]['clusters'])\n","print('These are all the coreferent mentions in the sample document ', dmentions)\n","print('These are the mentions mapped to unique ids denoting their order in the document ', dment_map)\n","print('These are the cluster ids of the ordered mentions', dcluster_ids)\n","print('There are %d mentions in the document titled \\'%s\\'' %(dnum_mentions, dummy_dataset[0]['doc_key']))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["These are all the coreferent mentions in the sample document  [(0, 2), (5, 5), (10, 10), (17, 19), (23, 24), (26, 26)]\n","These are the mentions mapped to unique ids denoting their order in the document  {(0, 2): 0, (5, 5): 1, (10, 10): 2, (17, 19): 3, (23, 24): 4, (26, 26): 5}\n","These are the cluster ids of the ordered mentions [0, 0, 0, 1, 0, 1]\n","There are 6 mentions in the document titled 'large_cat'\n"]}]},{"cell_type":"markdown","metadata":{"id":"RvrRxjHiX_s8"},"source":["###**4.2 Turning the sentences into embeddings and the mention indices into vectors**\n","\n","Using the next block of code, you can generate the padded document embeddings, and a copy of the mention starts and end indices adjusted for padding. "]},{"cell_type":"code","metadata":{"id":"NlOAWoL3Wv0l"},"source":["def tensorize_doc_sentences(sentences, mentions):\n","    starts, ends = [],[]\n","    sent_lengths = [len(sent) for sent in sentences]  # the actual, unpadded length of each sentence\n","    max_sent_length = max(sent_lengths)\n","\n","    # by padding each sentence to the maximum length, the embedded document will a new dimension\n","    embedded_sentences = np.zeros([1, len(sentences), max_sent_length, EMBEDDING_SIZE])\n","\n","    # in this block, we adjust the mention indices to reflect the added padding.\n","    sent_start = 0\n","    sent_start_after_padding = 0\n","    offset = 0\n","    for i, sent in enumerate(sentences):\n","        for m_start, m_end in mentions:\n","            if (sent_start <= m_start) & (m_end < sent_start + len(sent)):\n","                starts.append(m_start + offset)\n","                ends.append(m_end + offset)\n","        sent_start += len(sent)\n","        sent_start_after_padding += max_sent_length\n","        offset += max_sent_length - len(sent)\n","\n","        # Populate the the embedding tensor with the appropriate word embeddings.\n","        for j, word in enumerate(sent):\n","                embedded_word = EMBEDDING_DICT[word]\n","                embedded_sentences[0, i, j] = embedded_word\n","\n","\n","    return embedded_sentences, starts, ends"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6pUm4-blXxpb"},"source":["dsents_embedded, dstarts, dends = tensorize_doc_sentences(dummy_dataset[0]['sentences'], dmentions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C40AGj8zYjRk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b21224ef-6a9b-4632-c884-7428a48ad27f","executionInfo":{"status":"ok","timestamp":1682160843937,"user_tz":-60,"elapsed":13,"user":{"displayName":"Lydia Franklin","userId":"02300291642349467188"}}},"source":["print('%d document with %d sentences, each with a maximum of %d words, encoded as %d dimensional vectors' %(dsents_embedded.shape[0], dsents_embedded.shape[1], dsents_embedded.shape[2], dsents_embedded.shape[3])) \n","print('Mention starts: ', dstarts)\n","print('Mention ends: ', dends)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1 document with 4 sentences, each with a maximum of 12 words, encoded as 300 dimensional vectors\n","Mention starts:  [0, 12, 17, 24, 36, 39]\n","Mention ends:  [2, 12, 17, 26, 37, 39]\n"]}]},{"cell_type":"markdown","metadata":{"id":"2Ks-fpwFaVOp"},"source":["###**4.3. Generating Mention Pairs**\n","\n","This next function generates the example pairs for training or evaluation. For each mention (anaphor), candidate antecedents are any mentions preceeding it.\n","\n","<br>\n","\n","Here, during training we choose up to 250 antecedents (i.e. MAX_ANT = 250) and maintain a 2:1 negative to positive example ratio i.e. NEG_RATIO=2. (choosing this ratio can be challenging as you want ample examples to learn from but at the same time do not want the positive examples to be overshadowed by the negative ones).\n","\n","<br>\n","\n","At test time, we generate up to MAX_ANT examples without paying attention to the example ratio. We also do not generate training labels for the pairs."]},{"cell_type":"code","metadata":{"id":"1caJxj6maIcn"},"source":["# the maximum number of candidate antecedents we will give to each of the candidate mentions.\n","MAX_ANT = 250\n","\n","# the ratio of negative to postive examples\n","NEG_RATIO = 2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qjP4hwrZlNIj"},"source":["\n","\n","Study the function below and see the sample outputs."]},{"cell_type":"code","metadata":{"id":"Ibkw-OMulKF-"},"source":["def generate_pairs(num_mentions, cluster_ids, starts, ends, raw_starts, raw_ends, is_training, neg_ratio=NEG_RATIO, max_ant=MAX_ANT):\n","    mention_pairs = [[]]\n","    mention_pair_labels = [[]]\n","    raw_mention_pairs = []\n","\n","    # for the training set, we want labels. We also want to pay heed to the positive:negative example ratio\n","    if is_training:\n","        for ana in range(num_mentions):\n","            pos = 1\n","            # each anaphor must not have more that MAX_ANT candidate antecedents\n","            s = 0 if ana < max_ant else (ana - max_ant)\n","            for ant in range(s, ana):\n","                # two mentions are coreferent if they are in the same cluster\n","                l = cluster_ids[ana] == cluster_ids[ant]\n","                # if it's a positive example, add it\n","                if l:\n","                    pos += neg_ratio\n","                    mention_pairs[0].append([starts[ana],ends[ana],starts[ant],ends[ant]])\n","                    mention_pair_labels[0].append(1)\n","                # if it's a negative example, check that we don't already have twice as \n","                # many negative examples as positive ones before adding it\n","                elif pos > 0:\n","                    pos -=1\n","                    mention_pairs[0].append([starts[ana],ends[ana],starts[ant],ends[ant]])\n","                    mention_pair_labels[0].append(0)\n","\n","    # for the test set, add the pairs without balancing or labels\n","    else:\n","        for ana in range(num_mentions):\n","            s = 0 if ana < max_ant else (ana - max_ant)\n","            for ant in range(s,ana):\n","                mention_pairs[0].append([starts[ana], ends[ana], starts[ant], ends[ant]])\n","                # here we also add the original mention indices for unpadded evaluation.\n","                raw_mention_pairs.append([(raw_starts[ana], raw_ends[ana]), (raw_starts[ant], raw_ends[ant])])\n","    \n","\n","    return mention_pairs, mention_pair_labels, raw_mention_pairs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8PLwCe5Nxwi2","colab":{"base_uri":"https://localhost:8080/"},"outputId":"59f72d65-fc3b-462c-8850-674a944447d0","executionInfo":{"status":"ok","timestamp":1682160844230,"user_tz":-60,"elapsed":302,"user":{"displayName":"Lydia Franklin","userId":"02300291642349467188"}}},"source":["# A sample for training. Maximum of 4 antecedents per mention a 2:1 negative example ratio: positive example. No need to save the raw starts/ends\n","dmpairs, dpair_labels, draw_pairs = generate_pairs(dnum_mentions, dcluster_ids, dstarts, dends, None, None, True, 1, 4)\n","\n","from tabulate import tabulate\n","print(tabulate(zip(dmpairs[0], dpair_labels[0]), headers=['Ana_Ant pair', 'Pair label (padded)', ]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ana_Ant pair        Pair label (padded)\n","----------------  ---------------------\n","[12, 12, 0, 2]                        1\n","[17, 17, 0, 2]                        1\n","[17, 17, 12, 12]                      1\n","[24, 26, 0, 2]                        0\n","[36, 37, 0, 2]                        1\n","[36, 37, 12, 12]                      1\n","[36, 37, 17, 17]                      1\n","[36, 37, 24, 26]                      0\n","[39, 39, 12, 12]                      0\n","[39, 39, 24, 26]                      1\n","[39, 39, 36, 37]                      0\n"]}]},{"cell_type":"code","metadata":{"id":"IrgtEVgLxAme","colab":{"base_uri":"https://localhost:8080/"},"outputId":"742634ad-edbe-4d61-b97f-ac5152c92dcc","executionInfo":{"status":"ok","timestamp":1682160844231,"user_tz":-60,"elapsed":7,"user":{"displayName":"Lydia Franklin","userId":"02300291642349467188"}}},"source":["# A sample for evaluation. No labels necessary. Here we pair each mention with all its antecedents\n","draw_starts, draw_ends = zip(*dmentions)\n","dmpairs, dpair_labels, draw_pairs = generate_pairs(dnum_mentions, dcluster_ids, dstarts, dends, draw_starts, draw_ends, False)\n","\n","from tabulate import tabulate\n","print(tabulate(zip(draw_pairs, dmpairs[0]), headers=['Ana_Ant pair (unpadded)', 'Ana_Ant pair (padded)', ]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ana_Ant pair (unpadded)    Ana_Ant pair (padded)\n","-------------------------  -----------------------\n","[(5, 5), (0, 2)]           [12, 12, 0, 2]\n","[(10, 10), (0, 2)]         [17, 17, 0, 2]\n","[(10, 10), (5, 5)]         [17, 17, 12, 12]\n","[(17, 19), (0, 2)]         [24, 26, 0, 2]\n","[(17, 19), (5, 5)]         [24, 26, 12, 12]\n","[(17, 19), (10, 10)]       [24, 26, 17, 17]\n","[(23, 24), (0, 2)]         [36, 37, 0, 2]\n","[(23, 24), (5, 5)]         [36, 37, 12, 12]\n","[(23, 24), (10, 10)]       [36, 37, 17, 17]\n","[(23, 24), (17, 19)]       [36, 37, 24, 26]\n","[(26, 26), (0, 2)]         [39, 39, 0, 2]\n","[(26, 26), (5, 5)]         [39, 39, 12, 12]\n","[(26, 26), (10, 10)]       [39, 39, 17, 17]\n","[(26, 26), (17, 19)]       [39, 39, 24, 26]\n","[(26, 26), (23, 24)]       [39, 39, 36, 37]\n"]}]},{"cell_type":"markdown","metadata":{"id":"0QukrGCo4sVc"},"source":["### **4.4. Preprocessing and loading the dataset**\n","\n","Now, you will prepare the dataset for the coreference resolution model. Preprocessing step is an important step and depends on the target language. For Arabic, removing diacritics (accents that are written  above, below or on top of certain letters)may improve the overall performance."]},{"cell_type":"code","metadata":{"id":"E0iI7wBh5rUo"},"source":["import re, json\n","\n","def preprocess_arabic_text(text):\n","  #diacrtic unicodes are found using regular expressions\n","  diacritics_unicode = re.compile(r'[\\u0617-\\u061A\\u064B-\\u0652]')\n","  #the diacrtics are then removed\n","  text = re.sub(diacritics_unicode, \"\", text)\n","  return text\n","\n","def get_data(json_file, is_training, preprocess_text):\n","    processed_docs = []\n","\n","    for line in open(json_file):\n","\n","      # read the document in\n","      doc = json.loads(line)\n","      \n","      # check that there are coreferent mentions in this document\n","      clusters = doc['clusters']\n","\n","      sentences = doc['sentences']\n","\n","      if(preprocess_text==True):\n","          preprocessed_sents = [[preprocess_arabic_text(t) for t in sent] for sent in sentences]\n","          doc['sentences'] = preprocessed_sents\n","      \n","      if len(clusters) == 0:\n","          continue\n","\n","      #  get the mentions and their cluster information.\n","      gold_mentions, gold_mention_map, cluster_ids, num_mentions = get_mentions(clusters) # TASK 1.1 YOUR CODE HERE\n","\n","      # splits the mentions into two arrays, one representing the start indices, \n","      # and the other for the end indices\n","      raw_starts, raw_ends = zip(*gold_mentions)\n","\n","      # pad sentences, create glove sentence embeddings, create mention starts and ends for padded document\n","      word_emb, starts, ends = tensorize_doc_sentences(sentences, gold_mentions) # TASK 1.2 YOUR CODE HERE\n","\n","      # generate (anaphor, antecedent) pairs and their labels\n","      mention_pairs, mention_pair_labels, raw_mention_pairs = generate_pairs(num_mentions, cluster_ids, starts, ends, raw_starts, raw_ends, is_training) # TASK 1.3 YOUR CODE HERE\n","      mention_pairs, mention_pair_labels = np.array(mention_pairs),np.array(mention_pair_labels)\n","\n","      # add the processed document to the list\n","      processed_docs.append((word_emb, mention_pairs, mention_pair_labels, clusters, raw_mention_pairs))\n","\n","    return processed_docs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ky4ukJeB42nA"},"source":["#get_data(json_file, is_training_preprocess_text) receives three inputs: \n","#json_file (str) : the path to json file, preprocess_text)\n","#is_training (boolean): this is used to with generate_pairs(...) function to balance the number of generated pairs\n","#preprocess_text (boolean): whether to preprocess text or not \n","\n","DEV_DATA = get_data(DEV_PATH, False, True)\n","TEST_DATA = get_data(TEST_PATH, False, True)\n","TRAIN_DATA = get_data(TRAIN_PATH, True, True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8T-yYog5t4iD"},"source":["##**5. Building the Coreference Model**\n","\n","In this section, we will build the coreference resolution model. There are many ways to learn coreference, in this lab, we will be building a simplified version of a mention pair classification model. \n","\n","<br>\n","\n","Given a pair of mentions, (anaphor, antecedent), a mention pair classifier produces a single score between 0 and 1, representing the probability that the given pair is coreferent. We will use keras to take in the processed data we prepared in section 4 and produce mention pair scores for the given pairs."]},{"cell_type":"markdown","metadata":{"id":"GGp8agamJ0gc"},"source":["###**5.1 First, we will initialize model parameters.**"]},{"cell_type":"code","metadata":{"id":"ZmVyZ6XFISdd"},"source":["# the dimension of the pretrained embeddings\n","EMBEDDING_SIZE = 300\n","\n","# dropout rate for word embeddings\n","EMBEDDING_DROPOUT_RATE = 0.5\n","\n","# the size of the hidden layer, include both LSTM and feedforward NN\n","HIDDEN_SIZE = 50\n","\n","# the number of hidden layers used for the feedforward NN\n","NUM_FFN_LAYER = 2\n","\n","# the dropout rate for the hidden layers of LSTM and feedforward NN\n","HIDDEN_DROPOUT_RATE = 0.2\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KXkdiV0AJ8Sq"},"source":["###**5.2 Building the model**\n","\n","In the next cell block, you will complete the build function by doing completing the steps that follow.\n","\n","1. **Initialize the model inputs**\n","\n","(a.) Using the keras input layer (already imported) initialize the two input layers\n"," `word_embeddings` and `mention_pairs`.\n"," \n","**Hints:**\n","*  The dimension for this input is `(batch_size X num_sents X num_words X embedding_size)` where batch_size is the number of inputs at each time step. Our batch size is 1 document.\n","*  As always, we do not need to specify the batch_size to the model (i.e. the first dimension is not included in the `shape` parameter of `Input()`.\n","*  The shape parameter is thus a tuple of 3 elements `(num_sents, num_words, embedding_size)`. The first two parameters vary accross documents but no matter, keras can infer them. You only need to specify the third (-1) element in the tuple.\n","*  The dimension for this input is  `(batch_size X num_mention_pairs  X 4)`.\n","\n","    A line of code has been written for you to squeeze the word_embeddings after they have been created to remove the document dimension as the LSTMs only take 3 dimensional inputs\n","\n","    `word_embeddings_no_batch = Lambda(lambda x: K.squeeze(x,0))(word_embeddings)`\n","\n","    <br>\n","\n","(b.) Apply `EMBEDDING_DROPOUT_RATE` dropout to this no-batch word embeddings\n","\n","<br>\n","\n","2. **Encode the document using Bidirectional LSTMs**\n","\n","\n","For task 1 we will be working at the beginning of the build() method. The task is to create a bidirectional LSTM to encode the sentences from both directions, which provides context information to the coreference system.\n","\n","**Hints:**\n","* You'll need:\n","The dropout rate  of the hidden layers: `HIDDEN_DROPOUT_RATE`\n","The size of the lstm hidden layers: `HIDDEN_SIZE`\n","\n","* You need to create a two layer bidirectional LSTM (BiLSTMs) by stacking two LSTM() layers wrapped with Bidirectional() layers. The BiLSTMs need to return the output for all the tokens in the sentences, not just the final one. The output of the BiLSTMs should be called word_output. Here is an example of how to create a BiLSTMs using keras: https://keras.io/examples/imdb_bidirectional_lstm/.\n","\n","* Inorder to return the output for all the tokens in the sentences, i.e. a `(num_sents X num_words X HIDDEN_SIZE)` tensor, you will need to set the return_sequences attribute to True. The default setting is to return only the final output of the LSTM. And don’t forget to apply the recurrent_dropout.\n","\n","<br>\n","\n","We then flatten the output of the lstms to get a `(num_sents*num_words X HIDDEN_SIZE)` tensor using the Lambda function. This will help us gather the right indices for the mention pairs. We also apply further dropout.\n","\n","`flatten_word_output = Lambda(lambda x:K.reshape(x, [-1, 2 * HIDDEN_SIZE]))(word_output)`\n","\n","`flatten_word_output = Dropout(HIDDEN_DROPOUT_RATE)(flatten_word_output)`\n","\n","\n","<br>\n","\n","Then, we get the mention pair representations by first collecting the learned embeddings for each the words represented by [anaphor_start, anaphor_end, antecedent_start, antecedent_end] for each pair. We retain the document dimension (i.e. batch_size) for this input.\n","\n","`mention_pair_emb = Lambda(lambda x: K.gather(x[0], x[1]))([flatten_word_output, mention_pairs])`\n","\n","Then concatenating the embeddings such that each mention pair is represented by a `4 X HIDDEN_SIZE` tensor.\n","\n","`ffnn_input = Reshape((-1,8*HIDDEN_SIZE))(mention_pair_emb)`\n","\n","`ffnn_input` is thus a `batch_size X num_mention_pairs X 400` tensor\n","\n","<br>\n","\n","3. **Create a multilayer feed-forward neural network to compute the mention-pair scores.**\n","\n","Then you are required to create a FFNN that contains 2 hidden layers and an output layer. The outputs of the FFNN are  mention_pair_scores. Here are some requirements:\n","\n","The hidden layers need to have a size of `HIDDEN_SIZE`\n","You need to apply dropout after each the hidden layers (but not the output layer). The outputs are called mention_pair_scores\n","\n","**Hint:** \n","\n","Each hidden layer of the FFNN is a simple Dense() with an relu activation function. Layers are simply stacked together the output of the previous layer is the input for the next layer. To apply the dropout you can simply use the Dropout() layer. The output layer is slightly different, since it will have an output size of 1. Also in order to compute the binary cross entropy loss we need to give this final layer a sigmoid activation function.\n","\n","After computing the mention_pair_scores you will need to remove the last dimension of it, since the last dimension is always 1. But be careful this time we will need to retain the batch dimension (for compute the loss and training accuracy). Again you can use the K.squeeze() method wrapped with a Lambda layer.\n","The final output `mention_pair_scores` should be a `batch_size X num_mention_pairs` tensor.\n"]},{"cell_type":"code","metadata":{"id":"h5-NZADY5vGQ"},"source":["def build_model():\n","    # 1 (a.) Initialize the model inputs\n","    word_embeddings = Input((None,None,EMBEDDING_SIZE)) # YOUR CODE HERE\n","    mention_pairs = Input((None,4), dtype=\"int32\") # TASK 2.1a YOUR CODE HERE\n","    # squeeze the (batch_size X num_sents X num_words X embedding_size) into a \n","    # (num_sents X num_words X embedding_size) tensor\n","    word_embeddings_no_batch = Lambda(lambda x: K.squeeze(x,0))(word_embeddings)\n","\n","    # 1 (b.). Apply embedding dropout to the squeezed embeddings.\n","    word_embeddings_dropped = Dropout(EMBEDDING_DROPOUT_RATE)(word_embeddings_no_batch) # TASK 2.1b YOUR CODE HERE\n","\n","    # TASK 2.2. YOU CREATE A TWO LAYER BIDIRECTIONAL LSTM\n","    word_output = Bidirectional(LSTM(HIDDEN_SIZE, recurrent_dropout=HIDDEN_DROPOUT_RATE, return_sequences=True))(word_embeddings_dropped)\n","    word_output = Bidirectional(LSTM(HIDDEN_SIZE, recurrent_dropout=HIDDEN_DROPOUT_RATE, return_sequences=True))(word_output)\n","\n","    # flattening the lstms output and apply dropout.\n","    flatten_word_output = Lambda(lambda x:K.reshape(x, [-1, 2 * HIDDEN_SIZE]))(word_output)\n","    flatten_word_output = Dropout(HIDDEN_DROPOUT_RATE)(flatten_word_output)\n","\n","    # we gather the embeddings represented by [anaphor_start, anaphor_end, antecedent_start, antecedent_end] for each pair.\n","    mention_pair_emb = Lambda(lambda x: K.gather(x[0], x[1]))([flatten_word_output, mention_pairs])\n","\n","    # we flatten them such that each mention_pair is represented by a 400D tensor.\n","    ffnn_input = Reshape((-1,8*HIDDEN_SIZE))(mention_pair_emb)\n","\n","    # TASK 2.3. CREATE THE MULTILAYER PERCEPTRONS THEN SQUEEZE OUT THE LAST DIMENSION USING LAMBDA \n","    ffnn = Dense(HIDDEN_SIZE, activation=\"relu\")(ffnn_input)\n","    ffnn = Dropout(HIDDEN_DROPOUT_RATE)(ffnn)\n","    ffnn = Dense(HIDDEN_SIZE, activation=\"relu\")(ffnn)\n","    ffnn = Dropout(HIDDEN_DROPOUT_RATE)(ffnn)\n","\n","    ffnn_out = Dense(1, activation=\"sigmoid\")(ffnn)\n","\n","    mention_pair_scores = Lambda(lambda x: K.squeeze(x, -1))(ffnn_out)\n","\n","    model = Model(inputs=[word_embeddings,mention_pairs], outputs=mention_pair_scores)\n","    model.compile(optimizer='adam',loss='binary_crossentropy')\n","    model.summary()\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"huNfKPWudNkW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682160858865,"user_tz":-60,"elapsed":1089,"user":{"displayName":"Lydia Franklin","userId":"02300291642349467188"}},"outputId":"63314054-0af3-4385-ee96-d4f84dd63264"},"source":["model = build_model()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, None, None,  0           []                               \n","                                 300)]                                                            \n","                                                                                                  \n"," lambda (Lambda)                (None, None, 300)    0           ['input_1[0][0]']                \n","                                                                                                  \n"," dropout (Dropout)              (None, None, 300)    0           ['lambda[0][0]']                 \n","                                                                                                  \n"," bidirectional (Bidirectional)  (None, None, 100)    140400      ['dropout[0][0]']                \n","                                                                                                  \n"," bidirectional_1 (Bidirectional  (None, None, 100)   60400       ['bidirectional[0][0]']          \n"," )                                                                                                \n","                                                                                                  \n"," lambda_1 (Lambda)              (None, 100)          0           ['bidirectional_1[0][0]']        \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 100)          0           ['lambda_1[0][0]']               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, None, 4)]    0           []                               \n","                                                                                                  \n"," lambda_2 (Lambda)              (None, None, 4, 100  0           ['dropout_1[0][0]',              \n","                                )                                 'input_2[0][0]']                \n","                                                                                                  \n"," reshape (Reshape)              (None, None, 400)    0           ['lambda_2[0][0]']               \n","                                                                                                  \n"," dense (Dense)                  (None, None, 50)     20050       ['reshape[0][0]']                \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, None, 50)     0           ['dense[0][0]']                  \n","                                                                                                  \n"," dense_1 (Dense)                (None, None, 50)     2550        ['dropout_2[0][0]']              \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, None, 50)     0           ['dense_1[0][0]']                \n","                                                                                                  \n"," dense_2 (Dense)                (None, None, 1)      51          ['dropout_3[0][0]']              \n","                                                                                                  \n"," lambda_3 (Lambda)              (None, None)         0           ['dense_2[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 223,451\n","Trainable params: 223,451\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"kvzxGGeBvSme"},"source":["##**6. Coreference Resolution Evaluation**\n","\n","Coreference Resolution models are not evaluated using regular accuracy or f1 as one would evaluate a text classification model. Rather, using the pairwise scores produced by the system, we build coreference clusters. These clusters are\n","then evaluated using the CONLL score https://www.aclweb.org/anthology/W12-4501/ \n","In this section, we build functions to build such clusters."]},{"cell_type":"markdown","metadata":{"id":"dp0Db-2424KT"},"source":["###**6.1 Getting the Predicted clusters**\n","\n","First, we will write a function that takes a pair of mentions and produces two variables:\n","\n","1. `predicted_clusters`: a list of tuples. Each tuple is a cluster (i.e. the elements of each tuple are the mentions predicted to belong to that cluster, where each mention is a (start_index, end_index) tuple.\n","\n","2. `mention_to_predicted`: a dictionary whose keys are mentions and whose values are predicted clusters for the given mention\n","\n","The input to the function `mention_pairs` is the list of predicted mention pairs\n","[[(anaphor_start, anaphor_end), (antecedent_start, antecedent_end)], ...] similar to draw_pairs in section 4."]},{"cell_type":"code","metadata":{"id":"F209Q1TSDHbD"},"source":["def get_predicted_clusters(mention_pairs):\n","    mention_to_predicted = {}\n","    predicted_clusters = []\n","    \n","    # for each mention and its predicted antecedent\n","    for anaphora, predicted_antecedent in mention_pairs:\n","        # if the predicted antecedent has been processed before as an anaphor\n","        if predicted_antecedent in mention_to_predicted:\n","            # then the predicted cluster for the anaphor is the same as the one for its predicted antecedent\n","            predicted_cluster = mention_to_predicted[predicted_antecedent]\n","        # otherwise, \n","        else:\n","            # create a new cluster, with the antecedent as the first mention in that cluster\n","            predicted_cluster = len(predicted_clusters) # the cluster number (it's order in the list of clusters)\n","            predicted_clusters.append([predicted_antecedent])\n","            mention_to_predicted[predicted_antecedent] = predicted_cluster\n","\n","        # now we know the right cluster for the anaphor, add it to that cluster\n","        predicted_clusters[predicted_cluster].append(anaphora)\n","        mention_to_predicted[anaphora] = predicted_cluster\n","\n","    # make the cluster list a cluster tuple. Lists can be dictionary keys; they are mutable and support item assignment.\n","    predicted_clusters = [tuple(pc) for pc in predicted_clusters]\n","    # get the {mention: complete cluster} map for the predictions.\n","    mention_to_predicted = {m: predicted_clusters[i] for m, i in mention_to_predicted.items()}\n","\n","    return predicted_clusters, mention_to_predicted"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aLY8Wejt5wR_"},"source":["###**6.2 Coreference evaluation for a given document**\n","\n","In this subsection you will complete the `evaluate_coref()` function for coref evaluation on a single document. \n","\n","<br>\n","\n","The `evaluate_coref()` function takes 3 parameters:\n","* `predicted_mention_pairs`: the list of predicted mention pairs\n","* `gold_clusters`: the gold cluster from the orginal document\n","* `evaluator`: a reference to an instance of metrics.CorefEvaluator()\n","You will use the first 2 parameters to create variables to run the `evaluator.update()` method.\n","\n","<br>\n","\n","The`evaluator.update()` method takes 3 parameters:\n","* `predicted_clusters`: from 5.1\n","*  `gold_clusters`: the gold cluster from the orginal document, each cluster transformed from a list to a tuple.\n","* `mention_to_predicted`: from 5.1\n","* `mention_to_gold`: the gold equivalent of  `mention_to_predicted`\n","\n","<br>\n","\n","Some of the code has been written for you. You complete the code below to generate the rest of it."]},{"cell_type":"code","metadata":{"id":"KC9CdNof-ZB8"},"source":[" def evaluate_coref(predicted_mention_pairs, gold_clusters, evaluator):\n","    \n","    g_m_v = get_mentions(gold_clusters)\n","\n","    mm = {}\n","    for cluster,index in g_m_v[1].items():\n","      mm.setdefault(g_m_v[2][index], [])\n","      mm[g_m_v[2][index]].append(cluster)\n","    # turn each cluster in the list of gold cluster into a tuple (rather than a list)\n","    gold_clusters = tuple(tuple(v) for v in mm.values()) # TASK 3.1 CODE HERE\n","    # print(gold_clusters)\n","\n","    # mention to gold is a {mention: cluster of mentions it belongs, including the present mention} map\n","    # TASK 3.2 WRITE CODE HERE TO GENERATE mention_to_gold from gold_clusters\n","\n","    mention_to_gold = {}\n","    for cluster in list(mm.values()):\n","      for mention in cluster:\n","        mention_to_gold[mention] = tuple(cluster)\n","\n","    # get the predicted_clusters and mention_to_predict using get_predicted_clusters()\n","    predicted_clusters, mention_to_predicted = get_predicted_clusters(predicted_mention_pairs) # TASK 3.3 CODE HERE\n","\n","    # run the evaluator using the parameters you've gotten\n","    evaluator.update(predicted_clusters, gold_clusters, mention_to_predicted, mention_to_gold)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tzIvWQ39_FFS"},"source":["###**6.3 Evaluating the model on all the data**"]},{"cell_type":"code","metadata":{"id":"ftA58laV50dS"},"source":["def eval(model, eval_docs):\n","    coref_evaluator = metrics.CorefEvaluator()\n","\n","    for word_embeddings, mention_pairs, _, gold_clusters, raw_mention_pairs in eval_docs:\n","\n","        # get the mention pair scores from the model\n","        mention_pair_scores = model.predict_on_batch([word_embeddings, mention_pairs])\n","\n","        predicted_antecedents = {}\n","        best_antecedent_scores = {}\n","        # for a given anaphor \n","        for (ana, ant), score in zip(raw_mention_pairs, mention_pair_scores[0]):\n","            # only candidate antecedents with (ana, ante) above 0.5 are considered as valid system proposed candidates\n","            if score >= 0.5 and score > best_antecedent_scores.get(ana,0):\n","                # we chose the best among these to be the predicted antecedent for that anaphor\n","                predicted_antecedents[ana] = ant\n","                best_antecedent_scores[ana] = score\n","\n","        # getting the [anaphor, antecedent] pairs.\n","        predicted_mention_pairs = [[k,v] for k,v in predicted_antecedents.items()]\n","\n","        # evaluate the predicted mention pairs \n","        evaluate_coref(predicted_mention_pairs, gold_clusters, coref_evaluator)\n","\n","    # afer evaluating each document, get the conll prf\n","    p, r, f = coref_evaluator.get_prf()\n","    print(\"Average F1 (py): {:.2f}%\".format(f * 100))\n","    print(\"Average precision (py): {:.2f}%\".format(p * 100))\n","    print(\"Average recall (py): {:.2f}%\".format(r * 100))\n","    return p,r,f"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jnGTurMXuwd8"},"source":["##**7. Training and Evaluating the Model the Coreference Model**"]},{"cell_type":"code","metadata":{"id":"iYv_t2gPulH4"},"source":["def time_used(start_time):\n","    curr_time = time.time()\n","    used_time = curr_time - start_time\n","    m = used_time // 60\n","    s = used_time - 60 * m\n","    return \"%d m %d s\" % (m, s)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j0Y_H90D8XPi"},"source":["def batch_generator(processed_data):\n","    random.shuffle(processed_data)\n","    for word_embeddings, mention_pairs, mention_pair_labels, _, _ in processed_data:\n","      yield [word_embeddings, mention_pairs], mention_pair_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s4VcVF5k8V2A"},"source":["def train(epochs, report=False):\n","    start_time = time.time()\n","    for epoch in range(epochs):\n","        print(\"\\nStarting training epoch {}/{}\".format(epoch + 1, epochs))\n","        epoch_time = time.time()\n","\n","        model.fit(batch_generator(TRAIN_DATA), steps_per_epoch=2775)\n","\n","        print(\"Time used for epoch {}: {}\".format(epoch + 1, time_used(epoch_time)))\n","        dev_time = time.time()\n","        print(\"Evaluating on dev set after epoch {}/{}:\".format(epoch + 1, epochs))\n","        eval(model, DEV_DATA)\n","        print(\"Time used for evaluate on dev set: {}\".format(time_used(dev_time)))\n","\n","    print(\"\\nTraining finished!\")\n","    print(\"Time used for training: {}\".format(time_used(start_time)))\n","\n","    print(\"\\nEvaluating on test set:\")\n","    test_time = time.time()\n","    p, r, f = eval(model, TEST_DATA)\n","    print(\"Time used for evaluate on test set: {}\".format(time_used(test_time)))\n","    if report == True:\n","      return p, r, f"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JlwLiXQUnM-V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682160998523,"user_tz":-60,"elapsed":139666,"user":{"displayName":"Lydia Franklin","userId":"02300291642349467188"}},"outputId":"459a1fdf-52eb-45b4-a692-823fc831f189"},"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","# train the model for 10 epochs\n","train(10)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Starting training epoch 1/10\n","  20/2775 [..............................] - ETA: 12:33 - loss: 0.6409"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 19s 2ms/step - loss: 0.6409\n","Time used for epoch 1: 0 m 23 s\n","Evaluating on dev set after epoch 1/10:\n","Average F1 (py): 0.00%\n","Average precision (py): 0.00%\n","Average recall (py): 0.00%\n","Time used for evaluate on dev set: 0 m 6 s\n","\n","Starting training epoch 2/10\n","  20/2775 [..............................] - ETA: 12:14 - loss: 0.5732"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.5732\n","Time used for epoch 2: 0 m 10 s\n","Evaluating on dev set after epoch 2/10:\n","Average F1 (py): 29.50%\n","Average precision (py): 34.25%\n","Average recall (py): 64.15%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 3/10\n","  20/2775 [..............................] - ETA: 12:41 - loss: 0.5148"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.5148\n","Time used for epoch 3: 0 m 10 s\n","Evaluating on dev set after epoch 3/10:\n","Average F1 (py): 29.68%\n","Average precision (py): 33.76%\n","Average recall (py): 65.56%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 4/10\n","  20/2775 [..............................] - ETA: 12:17 - loss: 0.4758"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.4758\n","Time used for epoch 4: 0 m 5 s\n","Evaluating on dev set after epoch 4/10:\n","Average F1 (py): 29.63%\n","Average precision (py): 33.36%\n","Average recall (py): 65.26%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 5/10\n","  20/2775 [..............................] - ETA: 16:31 - loss: 0.4479"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 7s 2ms/step - loss: 0.4479\n","Time used for epoch 5: 0 m 7 s\n","Evaluating on dev set after epoch 5/10:\n","Average F1 (py): 31.24%\n","Average precision (py): 37.12%\n","Average recall (py): 58.84%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 6/10\n","  20/2775 [..............................] - ETA: 13:01 - loss: 0.4396"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4396\n","Time used for epoch 6: 0 m 10 s\n","Evaluating on dev set after epoch 6/10:\n","Average F1 (py): 35.73%\n","Average precision (py): 45.46%\n","Average recall (py): 48.68%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 7/10\n","  20/2775 [..............................] - ETA: 12:17 - loss: 0.4204"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4204\n","Time used for epoch 7: 0 m 10 s\n","Evaluating on dev set after epoch 7/10:\n","Average F1 (py): 35.13%\n","Average precision (py): 41.83%\n","Average recall (py): 50.80%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 8/10\n","  20/2775 [..............................] - ETA: 12:22 - loss: 0.4177"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.4177\n","Time used for epoch 8: 0 m 10 s\n","Evaluating on dev set after epoch 8/10:\n","Average F1 (py): 37.64%\n","Average precision (py): 48.57%\n","Average recall (py): 48.40%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 9/10\n","  20/2775 [..............................] - ETA: 12:08 - loss: 0.4121"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.4121\n","Time used for epoch 9: 0 m 10 s\n","Evaluating on dev set after epoch 9/10:\n","Average F1 (py): 35.46%\n","Average precision (py): 41.52%\n","Average recall (py): 52.75%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 10/10\n","  20/2775 [..............................] - ETA: 12:16 - loss: 0.4002"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.4002\n","Time used for epoch 10: 0 m 5 s\n","Evaluating on dev set after epoch 10/10:\n","Average F1 (py): 32.22%\n","Average precision (py): 36.04%\n","Average recall (py): 58.00%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Training finished!\n","Time used for training: 2 m 12 s\n","\n","Evaluating on test set:\n","Average F1 (py): 30.01%\n","Average precision (py): 33.82%\n","Average recall (py): 55.78%\n","Time used for evaluate on test set: 0 m 6 s\n"]}]},{"cell_type":"markdown","source":["##**8. Questions:**\n","\n","\n","\n","*   Would the performance decrease if we do not preprocess the text? If yes (or no), then why?\n","*   Experiment with different values for max antecedent (MAX_ANT) and negative ratio (NEG_RATIO), what do you observe?\n","*   How would you improve the accuracy? \n","\n","\n"],"metadata":{"id":"O1gWNwkMSX8a"}},{"cell_type":"code","source":["MAX_ANTs = [200, 250, 300]\n","NEG_RATIOs = [1, 2, 3]\n","\n","results = []\n","\n","for MAX_ANT in MAX_ANTs:\n","  for NEG_RATIO in NEG_RATIOs:\n","    model = build_model()\n","    MAX_ANT = MAX_ANT\n","    NEG_RATIO = NEG_RATIO\n","    p, r, f = train(10, report=True)\n","    results.append({\"MAX_ANT\":MAX_ANT, \"NEG_RATIO\":NEG_RATIO, \n","                    \"precision\":p, \"recall\":r, \"f1\":f})"],"metadata":{"id":"avRynlSdbDO6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682162237906,"user_tz":-60,"elapsed":1239407,"user":{"displayName":"Lydia Franklin","userId":"02300291642349467188"}},"outputId":"8d79d910-f152-40e4-ac82-a5a44a080553"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_3 (InputLayer)           [(None, None, None,  0           []                               \n","                                 300)]                                                            \n","                                                                                                  \n"," lambda_4 (Lambda)              (None, None, 300)    0           ['input_3[0][0]']                \n","                                                                                                  \n"," dropout_4 (Dropout)            (None, None, 300)    0           ['lambda_4[0][0]']               \n","                                                                                                  \n"," bidirectional_2 (Bidirectional  (None, None, 100)   140400      ['dropout_4[0][0]']              \n"," )                                                                                                \n","                                                                                                  \n"," bidirectional_3 (Bidirectional  (None, None, 100)   60400       ['bidirectional_2[0][0]']        \n"," )                                                                                                \n","                                                                                                  \n"," lambda_5 (Lambda)              (None, 100)          0           ['bidirectional_3[0][0]']        \n","                                                                                                  \n"," dropout_5 (Dropout)            (None, 100)          0           ['lambda_5[0][0]']               \n","                                                                                                  \n"," input_4 (InputLayer)           [(None, None, 4)]    0           []                               \n","                                                                                                  \n"," lambda_6 (Lambda)              (None, None, 4, 100  0           ['dropout_5[0][0]',              \n","                                )                                 'input_4[0][0]']                \n","                                                                                                  \n"," reshape_1 (Reshape)            (None, None, 400)    0           ['lambda_6[0][0]']               \n","                                                                                                  \n"," dense_3 (Dense)                (None, None, 50)     20050       ['reshape_1[0][0]']              \n","                                                                                                  \n"," dropout_6 (Dropout)            (None, None, 50)     0           ['dense_3[0][0]']                \n","                                                                                                  \n"," dense_4 (Dense)                (None, None, 50)     2550        ['dropout_6[0][0]']              \n","                                                                                                  \n"," dropout_7 (Dropout)            (None, None, 50)     0           ['dense_4[0][0]']                \n","                                                                                                  \n"," dense_5 (Dense)                (None, None, 1)      51          ['dropout_7[0][0]']              \n","                                                                                                  \n"," lambda_7 (Lambda)              (None, None)         0           ['dense_5[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 223,451\n","Trainable params: 223,451\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","\n","Starting training epoch 1/10\n","  20/2775 [..............................] - ETA: 12:15 - loss: 0.6232"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 18s 2ms/step - loss: 0.6232\n","Time used for epoch 1: 0 m 23 s\n","Evaluating on dev set after epoch 1/10:\n","Average F1 (py): 29.11%\n","Average precision (py): 33.77%\n","Average recall (py): 58.45%\n","Time used for evaluate on dev set: 0 m 5 s\n","\n","Starting training epoch 2/10\n","  20/2775 [..............................] - ETA: 12:29 - loss: 0.5565"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.5565\n","Time used for epoch 2: 0 m 10 s\n","Evaluating on dev set after epoch 2/10:\n","Average F1 (py): 29.60%\n","Average precision (py): 34.20%\n","Average recall (py): 65.49%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 3/10\n","  20/2775 [..............................] - ETA: 12:15 - loss: 0.5069"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.5069\n","Time used for epoch 3: 0 m 10 s\n","Evaluating on dev set after epoch 3/10:\n","Average F1 (py): 29.66%\n","Average precision (py): 33.61%\n","Average recall (py): 65.97%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 4/10\n","  20/2775 [..............................] - ETA: 12:10 - loss: 0.4733"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.4733\n","Time used for epoch 4: 0 m 10 s\n","Evaluating on dev set after epoch 4/10:\n","Average F1 (py): 29.73%\n","Average precision (py): 33.49%\n","Average recall (py): 65.43%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 5/10\n","  20/2775 [..............................] - ETA: 12:30 - loss: 0.4541"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.4541\n","Time used for epoch 5: 0 m 10 s\n","Evaluating on dev set after epoch 5/10:\n","Average F1 (py): 29.51%\n","Average precision (py): 33.92%\n","Average recall (py): 65.76%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 6/10\n","  20/2775 [..............................] - ETA: 12:46 - loss: 0.4331"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4331\n","Time used for epoch 6: 0 m 5 s\n","Evaluating on dev set after epoch 6/10:\n","Average F1 (py): 30.34%\n","Average precision (py): 35.87%\n","Average recall (py): 63.85%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 7/10\n","  20/2775 [..............................] - ETA: 18:42 - loss: 0.4236"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 8s 3ms/step - loss: 0.4236\n","Time used for epoch 7: 0 m 10 s\n","Evaluating on dev set after epoch 7/10:\n","Average F1 (py): 31.28%\n","Average precision (py): 36.90%\n","Average recall (py): 59.22%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 8/10\n","  20/2775 [..............................] - ETA: 14:44 - loss: 0.4159"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4159\n","Time used for epoch 8: 0 m 6 s\n","Evaluating on dev set after epoch 8/10:\n","Average F1 (py): 32.70%\n","Average precision (py): 39.14%\n","Average recall (py): 56.45%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 9/10\n","  20/2775 [..............................] - ETA: 11:37 - loss: 0.4053"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.4053\n","Time used for epoch 9: 0 m 10 s\n","Evaluating on dev set after epoch 9/10:\n","Average F1 (py): 35.45%\n","Average precision (py): 44.96%\n","Average recall (py): 50.84%\n","Time used for evaluate on dev set: 0 m 4 s\n","\n","Starting training epoch 10/10\n","  20/2775 [..............................] - ETA: 12:20 - loss: 0.4038"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.4038\n","Time used for epoch 10: 0 m 5 s\n","Evaluating on dev set after epoch 10/10:\n","Average F1 (py): 32.48%\n","Average precision (py): 38.55%\n","Average recall (py): 57.00%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Training finished!\n","Time used for training: 2 m 15 s\n","\n","Evaluating on test set:\n","Average F1 (py): 30.08%\n","Average precision (py): 35.57%\n","Average recall (py): 56.19%\n","Time used for evaluate on test set: 0 m 7 s\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_5 (InputLayer)           [(None, None, None,  0           []                               \n","                                 300)]                                                            \n","                                                                                                  \n"," lambda_8 (Lambda)              (None, None, 300)    0           ['input_5[0][0]']                \n","                                                                                                  \n"," dropout_8 (Dropout)            (None, None, 300)    0           ['lambda_8[0][0]']               \n","                                                                                                  \n"," bidirectional_4 (Bidirectional  (None, None, 100)   140400      ['dropout_8[0][0]']              \n"," )                                                                                                \n","                                                                                                  \n"," bidirectional_5 (Bidirectional  (None, None, 100)   60400       ['bidirectional_4[0][0]']        \n"," )                                                                                                \n","                                                                                                  \n"," lambda_9 (Lambda)              (None, 100)          0           ['bidirectional_5[0][0]']        \n","                                                                                                  \n"," dropout_9 (Dropout)            (None, 100)          0           ['lambda_9[0][0]']               \n","                                                                                                  \n"," input_6 (InputLayer)           [(None, None, 4)]    0           []                               \n","                                                                                                  \n"," lambda_10 (Lambda)             (None, None, 4, 100  0           ['dropout_9[0][0]',              \n","                                )                                 'input_6[0][0]']                \n","                                                                                                  \n"," reshape_2 (Reshape)            (None, None, 400)    0           ['lambda_10[0][0]']              \n","                                                                                                  \n"," dense_6 (Dense)                (None, None, 50)     20050       ['reshape_2[0][0]']              \n","                                                                                                  \n"," dropout_10 (Dropout)           (None, None, 50)     0           ['dense_6[0][0]']                \n","                                                                                                  \n"," dense_7 (Dense)                (None, None, 50)     2550        ['dropout_10[0][0]']             \n","                                                                                                  \n"," dropout_11 (Dropout)           (None, None, 50)     0           ['dense_7[0][0]']                \n","                                                                                                  \n"," dense_8 (Dense)                (None, None, 1)      51          ['dropout_11[0][0]']             \n","                                                                                                  \n"," lambda_11 (Lambda)             (None, None)         0           ['dense_8[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 223,451\n","Trainable params: 223,451\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","\n","Starting training epoch 1/10\n","  20/2775 [..............................] - ETA: 14:24 - loss: 0.6456"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 18s 2ms/step - loss: 0.6456\n","Time used for epoch 1: 0 m 22 s\n","Evaluating on dev set after epoch 1/10:\n","Average F1 (py): 0.00%\n","Average precision (py): 0.00%\n","Average recall (py): 0.00%\n","Time used for evaluate on dev set: 0 m 6 s\n","\n","Starting training epoch 2/10\n","  20/2775 [..............................] - ETA: 13:26 - loss: 0.5832"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.5832\n","Time used for epoch 2: 0 m 6 s\n","Evaluating on dev set after epoch 2/10:\n","Average F1 (py): 29.57%\n","Average precision (py): 33.71%\n","Average recall (py): 63.35%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 3/10\n","  20/2775 [..............................] - ETA: 17:33 - loss: 0.5231"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 8s 3ms/step - loss: 0.5231\n","Time used for epoch 3: 0 m 10 s\n","Evaluating on dev set after epoch 3/10:\n","Average F1 (py): 29.64%\n","Average precision (py): 34.04%\n","Average recall (py): 65.94%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 4/10\n","  20/2775 [..............................] - ETA: 12:11 - loss: 0.4824"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.4824\n","Time used for epoch 4: 0 m 10 s\n","Evaluating on dev set after epoch 4/10:\n","Average F1 (py): 29.72%\n","Average precision (py): 33.78%\n","Average recall (py): 65.39%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 5/10\n","  20/2775 [..............................] - ETA: 12:26 - loss: 0.4531"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.4531\n","Time used for epoch 5: 0 m 10 s\n","Evaluating on dev set after epoch 5/10:\n","Average F1 (py): 29.76%\n","Average precision (py): 34.02%\n","Average recall (py): 65.26%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 6/10\n","  20/2775 [..............................] - ETA: 12:12 - loss: 0.4392"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.4392\n","Time used for epoch 6: 0 m 5 s\n","Evaluating on dev set after epoch 6/10:\n","Average F1 (py): 33.68%\n","Average precision (py): 41.76%\n","Average recall (py): 53.92%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 7/10\n","  20/2775 [..............................] - ETA: 14:30 - loss: 0.4242"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4242\n","Time used for epoch 7: 0 m 6 s\n","Evaluating on dev set after epoch 7/10:\n","Average F1 (py): 36.37%\n","Average precision (py): 48.01%\n","Average recall (py): 46.78%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 8/10\n","  20/2775 [..............................] - ETA: 15:57 - loss: 0.4135"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 7s 2ms/step - loss: 0.4135\n","Time used for epoch 8: 0 m 6 s\n","Evaluating on dev set after epoch 8/10:\n","Average F1 (py): 34.91%\n","Average precision (py): 44.73%\n","Average recall (py): 52.65%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 9/10\n","  20/2775 [..............................] - ETA: 12:08 - loss: 0.4067"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.4067\n","Time used for epoch 9: 0 m 10 s\n","Evaluating on dev set after epoch 9/10:\n","Average F1 (py): 36.67%\n","Average precision (py): 48.64%\n","Average recall (py): 50.27%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 10/10\n","  20/2775 [..............................] - ETA: 12:53 - loss: 0.4014"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4014\n","Time used for epoch 10: 0 m 5 s\n","Evaluating on dev set after epoch 10/10:\n","Average F1 (py): 37.78%\n","Average precision (py): 50.68%\n","Average recall (py): 48.76%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Training finished!\n","Time used for training: 2 m 7 s\n","\n","Evaluating on test set:\n","Average F1 (py): 35.86%\n","Average precision (py): 49.33%\n","Average recall (py): 46.17%\n","Time used for evaluate on test set: 0 m 9 s\n","Model: \"model_3\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_7 (InputLayer)           [(None, None, None,  0           []                               \n","                                 300)]                                                            \n","                                                                                                  \n"," lambda_12 (Lambda)             (None, None, 300)    0           ['input_7[0][0]']                \n","                                                                                                  \n"," dropout_12 (Dropout)           (None, None, 300)    0           ['lambda_12[0][0]']              \n","                                                                                                  \n"," bidirectional_6 (Bidirectional  (None, None, 100)   140400      ['dropout_12[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," bidirectional_7 (Bidirectional  (None, None, 100)   60400       ['bidirectional_6[0][0]']        \n"," )                                                                                                \n","                                                                                                  \n"," lambda_13 (Lambda)             (None, 100)          0           ['bidirectional_7[0][0]']        \n","                                                                                                  \n"," dropout_13 (Dropout)           (None, 100)          0           ['lambda_13[0][0]']              \n","                                                                                                  \n"," input_8 (InputLayer)           [(None, None, 4)]    0           []                               \n","                                                                                                  \n"," lambda_14 (Lambda)             (None, None, 4, 100  0           ['dropout_13[0][0]',             \n","                                )                                 'input_8[0][0]']                \n","                                                                                                  \n"," reshape_3 (Reshape)            (None, None, 400)    0           ['lambda_14[0][0]']              \n","                                                                                                  \n"," dense_9 (Dense)                (None, None, 50)     20050       ['reshape_3[0][0]']              \n","                                                                                                  \n"," dropout_14 (Dropout)           (None, None, 50)     0           ['dense_9[0][0]']                \n","                                                                                                  \n"," dense_10 (Dense)               (None, None, 50)     2550        ['dropout_14[0][0]']             \n","                                                                                                  \n"," dropout_15 (Dropout)           (None, None, 50)     0           ['dense_10[0][0]']               \n","                                                                                                  \n"," dense_11 (Dense)               (None, None, 1)      51          ['dropout_15[0][0]']             \n","                                                                                                  \n"," lambda_15 (Lambda)             (None, None)         0           ['dense_11[0][0]']               \n","                                                                                                  \n","==================================================================================================\n","Total params: 223,451\n","Trainable params: 223,451\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","\n","Starting training epoch 1/10\n","  20/2775 [..............................] - ETA: 12:28 - loss: 0.6478"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 18s 2ms/step - loss: 0.6478\n","Time used for epoch 1: 0 m 18 s\n","Evaluating on dev set after epoch 1/10:\n","Average F1 (py): 0.00%\n","Average precision (py): 0.00%\n","Average recall (py): 0.00%\n","Time used for evaluate on dev set: 0 m 9 s\n","\n","Starting training epoch 2/10\n","  20/2775 [..............................] - ETA: 14:26 - loss: 0.5870"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.5870\n","Time used for epoch 2: 0 m 6 s\n","Evaluating on dev set after epoch 2/10:\n","Average F1 (py): 29.59%\n","Average precision (py): 34.20%\n","Average recall (py): 64.80%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 3/10\n","  20/2775 [..............................] - ETA: 20:47 - loss: 0.5276"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 9s 3ms/step - loss: 0.5276\n","Time used for epoch 3: 0 m 10 s\n","Evaluating on dev set after epoch 3/10:\n","Average F1 (py): 29.65%\n","Average precision (py): 33.73%\n","Average recall (py): 65.56%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 4/10\n","  20/2775 [..............................] - ETA: 18:41 - loss: 0.4852"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 8s 3ms/step - loss: 0.4852\n","Time used for epoch 4: 0 m 10 s\n","Evaluating on dev set after epoch 4/10:\n","Average F1 (py): 29.69%\n","Average precision (py): 34.13%\n","Average recall (py): 66.02%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 5/10\n","  20/2775 [..............................] - ETA: 14:59 - loss: 0.4541"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 7s 2ms/step - loss: 0.4541\n","Time used for epoch 5: 0 m 10 s\n","Evaluating on dev set after epoch 5/10:\n","Average F1 (py): 32.63%\n","Average precision (py): 41.06%\n","Average recall (py): 55.30%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 6/10\n","  20/2775 [..............................] - ETA: 14:27 - loss: 0.4431"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4431\n","Time used for epoch 6: 0 m 6 s\n","Evaluating on dev set after epoch 6/10:\n","Average F1 (py): 35.47%\n","Average precision (py): 46.05%\n","Average recall (py): 51.09%\n","Time used for evaluate on dev set: 0 m 4 s\n","\n","Starting training epoch 7/10\n","  20/2775 [..............................] - ETA: 15:13 - loss: 0.4281"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 7s 2ms/step - loss: 0.4281\n","Time used for epoch 7: 0 m 6 s\n","Evaluating on dev set after epoch 7/10:\n","Average F1 (py): 36.69%\n","Average precision (py): 49.00%\n","Average recall (py): 49.44%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 8/10\n","  20/2775 [..............................] - ETA: 20:21 - loss: 0.4174"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 9s 3ms/step - loss: 0.4174\n","Time used for epoch 8: 0 m 8 s\n","Evaluating on dev set after epoch 8/10:\n","Average F1 (py): 37.07%\n","Average precision (py): 49.07%\n","Average recall (py): 48.01%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 9/10\n","  20/2775 [..............................] - ETA: 13:44 - loss: 0.4153"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4153\n","Time used for epoch 9: 0 m 6 s\n","Evaluating on dev set after epoch 9/10:\n","Average F1 (py): 36.17%\n","Average precision (py): 45.85%\n","Average recall (py): 49.71%\n","Time used for evaluate on dev set: 0 m 4 s\n","\n","Starting training epoch 10/10\n","  20/2775 [..............................] - ETA: 14:43 - loss: 0.4088"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 7s 2ms/step - loss: 0.4088\n","Time used for epoch 10: 0 m 6 s\n","Evaluating on dev set after epoch 10/10:\n","Average F1 (py): 35.95%\n","Average precision (py): 46.25%\n","Average recall (py): 50.60%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Training finished!\n","Time used for training: 2 m 7 s\n","\n","Evaluating on test set:\n","Average F1 (py): 34.26%\n","Average precision (py): 44.56%\n","Average recall (py): 47.83%\n","Time used for evaluate on test set: 0 m 7 s\n","Model: \"model_4\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_9 (InputLayer)           [(None, None, None,  0           []                               \n","                                 300)]                                                            \n","                                                                                                  \n"," lambda_16 (Lambda)             (None, None, 300)    0           ['input_9[0][0]']                \n","                                                                                                  \n"," dropout_16 (Dropout)           (None, None, 300)    0           ['lambda_16[0][0]']              \n","                                                                                                  \n"," bidirectional_8 (Bidirectional  (None, None, 100)   140400      ['dropout_16[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," bidirectional_9 (Bidirectional  (None, None, 100)   60400       ['bidirectional_8[0][0]']        \n"," )                                                                                                \n","                                                                                                  \n"," lambda_17 (Lambda)             (None, 100)          0           ['bidirectional_9[0][0]']        \n","                                                                                                  \n"," dropout_17 (Dropout)           (None, 100)          0           ['lambda_17[0][0]']              \n","                                                                                                  \n"," input_10 (InputLayer)          [(None, None, 4)]    0           []                               \n","                                                                                                  \n"," lambda_18 (Lambda)             (None, None, 4, 100  0           ['dropout_17[0][0]',             \n","                                )                                 'input_10[0][0]']               \n","                                                                                                  \n"," reshape_4 (Reshape)            (None, None, 400)    0           ['lambda_18[0][0]']              \n","                                                                                                  \n"," dense_12 (Dense)               (None, None, 50)     20050       ['reshape_4[0][0]']              \n","                                                                                                  \n"," dropout_18 (Dropout)           (None, None, 50)     0           ['dense_12[0][0]']               \n","                                                                                                  \n"," dense_13 (Dense)               (None, None, 50)     2550        ['dropout_18[0][0]']             \n","                                                                                                  \n"," dropout_19 (Dropout)           (None, None, 50)     0           ['dense_13[0][0]']               \n","                                                                                                  \n"," dense_14 (Dense)               (None, None, 1)      51          ['dropout_19[0][0]']             \n","                                                                                                  \n"," lambda_19 (Lambda)             (None, None)         0           ['dense_14[0][0]']               \n","                                                                                                  \n","==================================================================================================\n","Total params: 223,451\n","Trainable params: 223,451\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","\n","Starting training epoch 1/10\n","  20/2775 [..............................] - ETA: 13:51 - loss: 0.6414"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 19s 2ms/step - loss: 0.6414\n","Time used for epoch 1: 0 m 22 s\n","Evaluating on dev set after epoch 1/10:\n","Average F1 (py): 0.00%\n","Average precision (py): 0.00%\n","Average recall (py): 0.00%\n","Time used for evaluate on dev set: 0 m 6 s\n","\n","Starting training epoch 2/10\n","  20/2775 [..............................] - ETA: 12:17 - loss: 0.5857"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.5857\n","Time used for epoch 2: 0 m 5 s\n","Evaluating on dev set after epoch 2/10:\n","Average F1 (py): 29.35%\n","Average precision (py): 33.23%\n","Average recall (py): 63.31%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 3/10\n","  20/2775 [..............................] - ETA: 18:21 - loss: 0.5310"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 8s 3ms/step - loss: 0.5310\n","Time used for epoch 3: 0 m 10 s\n","Evaluating on dev set after epoch 3/10:\n","Average F1 (py): 29.65%\n","Average precision (py): 34.47%\n","Average recall (py): 65.84%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 4/10\n","  20/2775 [..............................] - ETA: 13:18 - loss: 0.4795"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4795\n","Time used for epoch 4: 0 m 10 s\n","Evaluating on dev set after epoch 4/10:\n","Average F1 (py): 29.67%\n","Average precision (py): 32.91%\n","Average recall (py): 65.51%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 5/10\n","  20/2775 [..............................] - ETA: 12:25 - loss: 0.4565"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.4565\n","Time used for epoch 5: 0 m 10 s\n","Evaluating on dev set after epoch 5/10:\n","Average F1 (py): 29.78%\n","Average precision (py): 34.07%\n","Average recall (py): 65.24%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 6/10\n","  20/2775 [..............................] - ETA: 12:33 - loss: 0.4405"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4405\n","Time used for epoch 6: 0 m 10 s\n","Evaluating on dev set after epoch 6/10:\n","Average F1 (py): 30.25%\n","Average precision (py): 35.11%\n","Average recall (py): 61.67%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 7/10\n","  20/2775 [..............................] - ETA: 12:17 - loss: 0.4303"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.4303\n","Time used for epoch 7: 0 m 5 s\n","Evaluating on dev set after epoch 7/10:\n","Average F1 (py): 32.10%\n","Average precision (py): 39.82%\n","Average recall (py): 56.21%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 8/10\n","  20/2775 [..............................] - ETA: 15:33 - loss: 0.4195"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 7s 2ms/step - loss: 0.4195\n","Time used for epoch 8: 0 m 6 s\n","Evaluating on dev set after epoch 8/10:\n","Average F1 (py): 31.18%\n","Average precision (py): 37.45%\n","Average recall (py): 58.61%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 9/10\n","  20/2775 [..............................] - ETA: 15:18 - loss: 0.4082"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 7s 2ms/step - loss: 0.4082\n","Time used for epoch 9: 0 m 6 s\n","Evaluating on dev set after epoch 9/10:\n","Average F1 (py): 32.87%\n","Average precision (py): 40.76%\n","Average recall (py): 55.63%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 10/10\n","  20/2775 [..............................] - ETA: 12:37 - loss: 0.4032"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4032\n","Time used for epoch 10: 0 m 5 s\n","Evaluating on dev set after epoch 10/10:\n","Average F1 (py): 33.41%\n","Average precision (py): 41.10%\n","Average recall (py): 54.27%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Training finished!\n","Time used for training: 2 m 5 s\n","\n","Evaluating on test set:\n","Average F1 (py): 31.17%\n","Average precision (py): 38.74%\n","Average recall (py): 52.43%\n","Time used for evaluate on test set: 0 m 7 s\n","Model: \"model_5\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_11 (InputLayer)          [(None, None, None,  0           []                               \n","                                 300)]                                                            \n","                                                                                                  \n"," lambda_20 (Lambda)             (None, None, 300)    0           ['input_11[0][0]']               \n","                                                                                                  \n"," dropout_20 (Dropout)           (None, None, 300)    0           ['lambda_20[0][0]']              \n","                                                                                                  \n"," bidirectional_10 (Bidirectiona  (None, None, 100)   140400      ['dropout_20[0][0]']             \n"," l)                                                                                               \n","                                                                                                  \n"," bidirectional_11 (Bidirectiona  (None, None, 100)   60400       ['bidirectional_10[0][0]']       \n"," l)                                                                                               \n","                                                                                                  \n"," lambda_21 (Lambda)             (None, 100)          0           ['bidirectional_11[0][0]']       \n","                                                                                                  \n"," dropout_21 (Dropout)           (None, 100)          0           ['lambda_21[0][0]']              \n","                                                                                                  \n"," input_12 (InputLayer)          [(None, None, 4)]    0           []                               \n","                                                                                                  \n"," lambda_22 (Lambda)             (None, None, 4, 100  0           ['dropout_21[0][0]',             \n","                                )                                 'input_12[0][0]']               \n","                                                                                                  \n"," reshape_5 (Reshape)            (None, None, 400)    0           ['lambda_22[0][0]']              \n","                                                                                                  \n"," dense_15 (Dense)               (None, None, 50)     20050       ['reshape_5[0][0]']              \n","                                                                                                  \n"," dropout_22 (Dropout)           (None, None, 50)     0           ['dense_15[0][0]']               \n","                                                                                                  \n"," dense_16 (Dense)               (None, None, 50)     2550        ['dropout_22[0][0]']             \n","                                                                                                  \n"," dropout_23 (Dropout)           (None, None, 50)     0           ['dense_16[0][0]']               \n","                                                                                                  \n"," dense_17 (Dense)               (None, None, 1)      51          ['dropout_23[0][0]']             \n","                                                                                                  \n"," lambda_23 (Lambda)             (None, None)         0           ['dense_17[0][0]']               \n","                                                                                                  \n","==================================================================================================\n","Total params: 223,451\n","Trainable params: 223,451\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","\n","Starting training epoch 1/10\n","  20/2775 [..............................] - ETA: 13:12 - loss: 0.6325"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 18s 2ms/step - loss: 0.6325\n","Time used for epoch 1: 0 m 22 s\n","Evaluating on dev set after epoch 1/10:\n","Average F1 (py): 0.00%\n","Average precision (py): 0.00%\n","Average recall (py): 0.00%\n","Time used for evaluate on dev set: 0 m 6 s\n","\n","Starting training epoch 2/10\n","  20/2775 [..............................] - ETA: 12:21 - loss: 0.5690"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.5690\n","Time used for epoch 2: 0 m 10 s\n","Evaluating on dev set after epoch 2/10:\n","Average F1 (py): 29.63%\n","Average precision (py): 33.91%\n","Average recall (py): 65.62%\n","Time used for evaluate on dev set: 0 m 4 s\n","\n","Starting training epoch 3/10\n","  20/2775 [..............................] - ETA: 12:42 - loss: 0.5094"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.5094\n","Time used for epoch 3: 0 m 5 s\n","Evaluating on dev set after epoch 3/10:\n","Average F1 (py): 29.70%\n","Average precision (py): 33.69%\n","Average recall (py): 65.93%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 4/10\n","  20/2775 [..............................] - ETA: 18:43 - loss: 0.4744"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 8s 3ms/step - loss: 0.4744\n","Time used for epoch 4: 0 m 10 s\n","Evaluating on dev set after epoch 4/10:\n","Average F1 (py): 29.70%\n","Average precision (py): 33.70%\n","Average recall (py): 65.54%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 5/10\n","  20/2775 [..............................] - ETA: 13:51 - loss: 0.4529"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4529\n","Time used for epoch 5: 0 m 6 s\n","Evaluating on dev set after epoch 5/10:\n","Average F1 (py): 29.82%\n","Average precision (py): 34.59%\n","Average recall (py): 64.57%\n","Time used for evaluate on dev set: 0 m 4 s\n","\n","Starting training epoch 6/10\n","  20/2775 [..............................] - ETA: 12:09 - loss: 0.4358"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.4358\n","Time used for epoch 6: 0 m 10 s\n","Evaluating on dev set after epoch 6/10:\n","Average F1 (py): 34.21%\n","Average precision (py): 43.79%\n","Average recall (py): 52.17%\n","Time used for evaluate on dev set: 0 m 4 s\n","\n","Starting training epoch 7/10\n","  20/2775 [..............................] - ETA: 12:25 - loss: 0.4244"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4244\n","Time used for epoch 7: 0 m 10 s\n","Evaluating on dev set after epoch 7/10:\n","Average F1 (py): 35.85%\n","Average precision (py): 47.29%\n","Average recall (py): 50.70%\n","Time used for evaluate on dev set: 0 m 4 s\n","\n","Starting training epoch 8/10\n","  20/2775 [..............................] - ETA: 13:13 - loss: 0.4082"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4082\n","Time used for epoch 8: 0 m 10 s\n","Evaluating on dev set after epoch 8/10:\n","Average F1 (py): 33.54%\n","Average precision (py): 41.93%\n","Average recall (py): 54.58%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 9/10\n","  20/2775 [..............................] - ETA: 15:16 - loss: 0.4084"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 7s 2ms/step - loss: 0.4084\n","Time used for epoch 9: 0 m 10 s\n","Evaluating on dev set after epoch 9/10:\n","Average F1 (py): 37.42%\n","Average precision (py): 48.61%\n","Average recall (py): 47.87%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 10/10\n","  20/2775 [..............................] - ETA: 18:56 - loss: 0.4030"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 8s 3ms/step - loss: 0.4030\n","Time used for epoch 10: 0 m 8 s\n","Evaluating on dev set after epoch 10/10:\n","Average F1 (py): 37.81%\n","Average precision (py): 49.59%\n","Average recall (py): 47.31%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Training finished!\n","Time used for training: 2 m 22 s\n","\n","Evaluating on test set:\n","Average F1 (py): 35.52%\n","Average precision (py): 47.01%\n","Average recall (py): 45.38%\n","Time used for evaluate on test set: 0 m 4 s\n","Model: \"model_6\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_13 (InputLayer)          [(None, None, None,  0           []                               \n","                                 300)]                                                            \n","                                                                                                  \n"," lambda_24 (Lambda)             (None, None, 300)    0           ['input_13[0][0]']               \n","                                                                                                  \n"," dropout_24 (Dropout)           (None, None, 300)    0           ['lambda_24[0][0]']              \n","                                                                                                  \n"," bidirectional_12 (Bidirectiona  (None, None, 100)   140400      ['dropout_24[0][0]']             \n"," l)                                                                                               \n","                                                                                                  \n"," bidirectional_13 (Bidirectiona  (None, None, 100)   60400       ['bidirectional_12[0][0]']       \n"," l)                                                                                               \n","                                                                                                  \n"," lambda_25 (Lambda)             (None, 100)          0           ['bidirectional_13[0][0]']       \n","                                                                                                  \n"," dropout_25 (Dropout)           (None, 100)          0           ['lambda_25[0][0]']              \n","                                                                                                  \n"," input_14 (InputLayer)          [(None, None, 4)]    0           []                               \n","                                                                                                  \n"," lambda_26 (Lambda)             (None, None, 4, 100  0           ['dropout_25[0][0]',             \n","                                )                                 'input_14[0][0]']               \n","                                                                                                  \n"," reshape_6 (Reshape)            (None, None, 400)    0           ['lambda_26[0][0]']              \n","                                                                                                  \n"," dense_18 (Dense)               (None, None, 50)     20050       ['reshape_6[0][0]']              \n","                                                                                                  \n"," dropout_26 (Dropout)           (None, None, 50)     0           ['dense_18[0][0]']               \n","                                                                                                  \n"," dense_19 (Dense)               (None, None, 50)     2550        ['dropout_26[0][0]']             \n","                                                                                                  \n"," dropout_27 (Dropout)           (None, None, 50)     0           ['dense_19[0][0]']               \n","                                                                                                  \n"," dense_20 (Dense)               (None, None, 1)      51          ['dropout_27[0][0]']             \n","                                                                                                  \n"," lambda_27 (Lambda)             (None, None)         0           ['dense_20[0][0]']               \n","                                                                                                  \n","==================================================================================================\n","Total params: 223,451\n","Trainable params: 223,451\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","\n","Starting training epoch 1/10\n","  20/2775 [..............................] - ETA: 18:22 - loss: 0.6415"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 21s 3ms/step - loss: 0.6415\n","Time used for epoch 1: 0 m 20 s\n","Evaluating on dev set after epoch 1/10:\n","Average F1 (py): 0.00%\n","Average precision (py): 0.00%\n","Average recall (py): 0.00%\n","Time used for evaluate on dev set: 0 m 4 s\n","\n","Starting training epoch 2/10\n","  20/2775 [..............................] - ETA: 12:07 - loss: 0.5835"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.5835\n","Time used for epoch 2: 0 m 5 s\n","Evaluating on dev set after epoch 2/10:\n","Average F1 (py): 31.62%\n","Average precision (py): 40.65%\n","Average recall (py): 43.99%\n","Time used for evaluate on dev set: 0 m 4 s\n","\n","Starting training epoch 3/10\n","  20/2775 [..............................] - ETA: 13:55 - loss: 0.5303"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.5303\n","Time used for epoch 3: 0 m 6 s\n","Evaluating on dev set after epoch 3/10:\n","Average F1 (py): 29.75%\n","Average precision (py): 33.95%\n","Average recall (py): 65.61%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 4/10\n","  20/2775 [..............................] - ETA: 16:17 - loss: 0.4759"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 7s 2ms/step - loss: 0.4759\n","Time used for epoch 4: 0 m 7 s\n","Evaluating on dev set after epoch 4/10:\n","Average F1 (py): 29.83%\n","Average precision (py): 33.42%\n","Average recall (py): 63.74%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 5/10\n","  20/2775 [..............................] - ETA: 12:18 - loss: 0.4488"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.4488\n","Time used for epoch 5: 0 m 10 s\n","Evaluating on dev set after epoch 5/10:\n","Average F1 (py): 31.94%\n","Average precision (py): 39.50%\n","Average recall (py): 56.94%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 6/10\n","  20/2775 [..............................] - ETA: 12:35 - loss: 0.4324"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.4324\n","Time used for epoch 6: 0 m 5 s\n","Evaluating on dev set after epoch 6/10:\n","Average F1 (py): 35.50%\n","Average precision (py): 47.34%\n","Average recall (py): 50.23%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 7/10\n","  20/2775 [..............................] - ETA: 18:50 - loss: 0.4222"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 8s 3ms/step - loss: 0.4222\n","Time used for epoch 7: 0 m 8 s\n","Evaluating on dev set after epoch 7/10:\n","Average F1 (py): 36.06%\n","Average precision (py): 48.53%\n","Average recall (py): 50.23%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 8/10\n","  20/2775 [..............................] - ETA: 12:44 - loss: 0.4162"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4162\n","Time used for epoch 8: 0 m 5 s\n","Evaluating on dev set after epoch 8/10:\n","Average F1 (py): 34.02%\n","Average precision (py): 43.92%\n","Average recall (py): 52.65%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 9/10\n","  20/2775 [..............................] - ETA: 15:29 - loss: 0.4102"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 7s 2ms/step - loss: 0.4102\n","Time used for epoch 9: 0 m 10 s\n","Evaluating on dev set after epoch 9/10:\n","Average F1 (py): 36.07%\n","Average precision (py): 48.09%\n","Average recall (py): 50.48%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 10/10\n","  20/2775 [..............................] - ETA: 18:31 - loss: 0.4054"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 8s 3ms/step - loss: 0.4054\n","Time used for epoch 10: 0 m 8 s\n","Evaluating on dev set after epoch 10/10:\n","Average F1 (py): 37.43%\n","Average precision (py): 50.57%\n","Average recall (py): 48.86%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Training finished!\n","Time used for training: 1 m 59 s\n","\n","Evaluating on test set:\n","Average F1 (py): 34.93%\n","Average precision (py): 47.55%\n","Average recall (py): 46.81%\n","Time used for evaluate on test set: 0 m 4 s\n","Model: \"model_7\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_15 (InputLayer)          [(None, None, None,  0           []                               \n","                                 300)]                                                            \n","                                                                                                  \n"," lambda_28 (Lambda)             (None, None, 300)    0           ['input_15[0][0]']               \n","                                                                                                  \n"," dropout_28 (Dropout)           (None, None, 300)    0           ['lambda_28[0][0]']              \n","                                                                                                  \n"," bidirectional_14 (Bidirectiona  (None, None, 100)   140400      ['dropout_28[0][0]']             \n"," l)                                                                                               \n","                                                                                                  \n"," bidirectional_15 (Bidirectiona  (None, None, 100)   60400       ['bidirectional_14[0][0]']       \n"," l)                                                                                               \n","                                                                                                  \n"," lambda_29 (Lambda)             (None, 100)          0           ['bidirectional_15[0][0]']       \n","                                                                                                  \n"," dropout_29 (Dropout)           (None, 100)          0           ['lambda_29[0][0]']              \n","                                                                                                  \n"," input_16 (InputLayer)          [(None, None, 4)]    0           []                               \n","                                                                                                  \n"," lambda_30 (Lambda)             (None, None, 4, 100  0           ['dropout_29[0][0]',             \n","                                )                                 'input_16[0][0]']               \n","                                                                                                  \n"," reshape_7 (Reshape)            (None, None, 400)    0           ['lambda_30[0][0]']              \n","                                                                                                  \n"," dense_21 (Dense)               (None, None, 50)     20050       ['reshape_7[0][0]']              \n","                                                                                                  \n"," dropout_30 (Dropout)           (None, None, 50)     0           ['dense_21[0][0]']               \n","                                                                                                  \n"," dense_22 (Dense)               (None, None, 50)     2550        ['dropout_30[0][0]']             \n","                                                                                                  \n"," dropout_31 (Dropout)           (None, None, 50)     0           ['dense_22[0][0]']               \n","                                                                                                  \n"," dense_23 (Dense)               (None, None, 1)      51          ['dropout_31[0][0]']             \n","                                                                                                  \n"," lambda_31 (Lambda)             (None, None)         0           ['dense_23[0][0]']               \n","                                                                                                  \n","==================================================================================================\n","Total params: 223,451\n","Trainable params: 223,451\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","\n","Starting training epoch 1/10\n","  20/2775 [..............................] - ETA: 16:11 - loss: 0.6415"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 26s 2ms/step - loss: 0.6415\n","Time used for epoch 1: 0 m 25 s\n","Evaluating on dev set after epoch 1/10:\n","Average F1 (py): 0.00%\n","Average precision (py): 0.00%\n","Average recall (py): 0.00%\n","Time used for evaluate on dev set: 0 m 4 s\n","\n","Starting training epoch 2/10\n","  20/2775 [..............................] - ETA: 19:14 - loss: 0.5814"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 9s 3ms/step - loss: 0.5814\n","Time used for epoch 2: 0 m 8 s\n","Evaluating on dev set after epoch 2/10:\n","Average F1 (py): 29.59%\n","Average precision (py): 35.05%\n","Average recall (py): 64.54%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 3/10\n","  20/2775 [..............................] - ETA: 18:40 - loss: 0.5186"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 8s 3ms/step - loss: 0.5186\n","Time used for epoch 3: 0 m 8 s\n","Evaluating on dev set after epoch 3/10:\n","Average F1 (py): 29.67%\n","Average precision (py): 33.85%\n","Average recall (py): 65.44%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 4/10\n","  20/2775 [..............................] - ETA: 14:39 - loss: 0.4793"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4793\n","Time used for epoch 4: 0 m 10 s\n","Evaluating on dev set after epoch 4/10:\n","Average F1 (py): 29.95%\n","Average precision (py): 34.95%\n","Average recall (py): 63.42%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 5/10\n","  20/2775 [..............................] - ETA: 14:37 - loss: 0.4540"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4540\n","Time used for epoch 5: 0 m 10 s\n","Evaluating on dev set after epoch 5/10:\n","Average F1 (py): 30.04%\n","Average precision (py): 34.38%\n","Average recall (py): 62.80%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 6/10\n","  20/2775 [..............................] - ETA: 13:59 - loss: 0.4356"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4356\n","Time used for epoch 6: 0 m 10 s\n","Evaluating on dev set after epoch 6/10:\n","Average F1 (py): 31.80%\n","Average precision (py): 39.19%\n","Average recall (py): 57.45%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 7/10\n","  20/2775 [..............................] - ETA: 14:47 - loss: 0.4260"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4260\n","Time used for epoch 7: 0 m 10 s\n","Evaluating on dev set after epoch 7/10:\n","Average F1 (py): 34.74%\n","Average precision (py): 44.48%\n","Average recall (py): 51.53%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 8/10\n","  20/2775 [..............................] - ETA: 14:14 - loss: 0.4195"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 7s 2ms/step - loss: 0.4195\n","Time used for epoch 8: 0 m 10 s\n","Evaluating on dev set after epoch 8/10:\n","Average F1 (py): 35.54%\n","Average precision (py): 47.16%\n","Average recall (py): 49.42%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 9/10\n","  20/2775 [..............................] - ETA: 14:22 - loss: 0.4112"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4112\n","Time used for epoch 9: 0 m 10 s\n","Evaluating on dev set after epoch 9/10:\n","Average F1 (py): 36.75%\n","Average precision (py): 49.70%\n","Average recall (py): 48.68%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 10/10\n","  20/2775 [..............................] - ETA: 14:13 - loss: 0.4031"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4031\n","Time used for epoch 10: 0 m 6 s\n","Evaluating on dev set after epoch 10/10:\n","Average F1 (py): 31.89%\n","Average precision (py): 37.07%\n","Average recall (py): 58.97%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Training finished!\n","Time used for training: 2 m 26 s\n","\n","Evaluating on test set:\n","Average F1 (py): 29.41%\n","Average precision (py): 35.01%\n","Average recall (py): 57.25%\n","Time used for evaluate on test set: 0 m 7 s\n","Model: \"model_8\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_17 (InputLayer)          [(None, None, None,  0           []                               \n","                                 300)]                                                            \n","                                                                                                  \n"," lambda_32 (Lambda)             (None, None, 300)    0           ['input_17[0][0]']               \n","                                                                                                  \n"," dropout_32 (Dropout)           (None, None, 300)    0           ['lambda_32[0][0]']              \n","                                                                                                  \n"," bidirectional_16 (Bidirectiona  (None, None, 100)   140400      ['dropout_32[0][0]']             \n"," l)                                                                                               \n","                                                                                                  \n"," bidirectional_17 (Bidirectiona  (None, None, 100)   60400       ['bidirectional_16[0][0]']       \n"," l)                                                                                               \n","                                                                                                  \n"," lambda_33 (Lambda)             (None, 100)          0           ['bidirectional_17[0][0]']       \n","                                                                                                  \n"," dropout_33 (Dropout)           (None, 100)          0           ['lambda_33[0][0]']              \n","                                                                                                  \n"," input_18 (InputLayer)          [(None, None, 4)]    0           []                               \n","                                                                                                  \n"," lambda_34 (Lambda)             (None, None, 4, 100  0           ['dropout_33[0][0]',             \n","                                )                                 'input_18[0][0]']               \n","                                                                                                  \n"," reshape_8 (Reshape)            (None, None, 400)    0           ['lambda_34[0][0]']              \n","                                                                                                  \n"," dense_24 (Dense)               (None, None, 50)     20050       ['reshape_8[0][0]']              \n","                                                                                                  \n"," dropout_34 (Dropout)           (None, None, 50)     0           ['dense_24[0][0]']               \n","                                                                                                  \n"," dense_25 (Dense)               (None, None, 50)     2550        ['dropout_34[0][0]']             \n","                                                                                                  \n"," dropout_35 (Dropout)           (None, None, 50)     0           ['dense_25[0][0]']               \n","                                                                                                  \n"," dense_26 (Dense)               (None, None, 1)      51          ['dropout_35[0][0]']             \n","                                                                                                  \n"," lambda_35 (Lambda)             (None, None)         0           ['dense_26[0][0]']               \n","                                                                                                  \n","==================================================================================================\n","Total params: 223,451\n","Trainable params: 223,451\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","\n","Starting training epoch 1/10\n","  20/2775 [..............................] - ETA: 12:52 - loss: 0.6268"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 19s 2ms/step - loss: 0.6268\n","Time used for epoch 1: 0 m 18 s\n","Evaluating on dev set after epoch 1/10:\n","Average F1 (py): 0.00%\n","Average precision (py): 0.00%\n","Average recall (py): 0.00%\n","Time used for evaluate on dev set: 0 m 5 s\n","\n","Starting training epoch 2/10\n","  20/2775 [..............................] - ETA: 15:58 - loss: 0.5723"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 7s 2ms/step - loss: 0.5723\n","Time used for epoch 2: 0 m 7 s\n","Evaluating on dev set after epoch 2/10:\n","Average F1 (py): 29.53%\n","Average precision (py): 34.12%\n","Average recall (py): 64.08%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 3/10\n","  20/2775 [..............................] - ETA: 16:16 - loss: 0.5139"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 7s 2ms/step - loss: 0.5139\n","Time used for epoch 3: 0 m 7 s\n","Evaluating on dev set after epoch 3/10:\n","Average F1 (py): 29.67%\n","Average precision (py): 34.63%\n","Average recall (py): 65.91%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 4/10\n","  20/2775 [..............................] - ETA: 12:42 - loss: 0.4708"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4708\n","Time used for epoch 4: 0 m 10 s\n","Evaluating on dev set after epoch 4/10:\n","Average F1 (py): 30.66%\n","Average precision (py): 35.47%\n","Average recall (py): 59.66%\n","Time used for evaluate on dev set: 0 m 3 s\n","\n","Starting training epoch 5/10\n","  20/2775 [..............................] - ETA: 13:15 - loss: 0.4448"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4448\n","Time used for epoch 5: 0 m 5 s\n","Evaluating on dev set after epoch 5/10:\n","Average F1 (py): 29.83%\n","Average precision (py): 34.09%\n","Average recall (py): 64.92%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 6/10\n","  20/2775 [..............................] - ETA: 19:00 - loss: 0.4301"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 8s 3ms/step - loss: 0.4301\n","Time used for epoch 6: 0 m 8 s\n","Evaluating on dev set after epoch 6/10:\n","Average F1 (py): 33.33%\n","Average precision (py): 41.20%\n","Average recall (py): 54.20%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 7/10\n","  20/2775 [..............................] - ETA: 12:41 - loss: 0.4189"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4189\n","Time used for epoch 7: 0 m 5 s\n","Evaluating on dev set after epoch 7/10:\n","Average F1 (py): 38.15%\n","Average precision (py): 53.44%\n","Average recall (py): 45.58%\n","Time used for evaluate on dev set: 0 m 4 s\n","\n","Starting training epoch 8/10\n","  20/2775 [..............................] - ETA: 13:39 - loss: 0.4176"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4176\n","Time used for epoch 8: 0 m 6 s\n","Evaluating on dev set after epoch 8/10:\n","Average F1 (py): 35.39%\n","Average precision (py): 46.79%\n","Average recall (py): 50.91%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 9/10\n","  20/2775 [..............................] - ETA: 18:44 - loss: 0.4054"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 8s 3ms/step - loss: 0.4054\n","Time used for epoch 9: 0 m 8 s\n","Evaluating on dev set after epoch 9/10:\n","Average F1 (py): 35.71%\n","Average precision (py): 45.72%\n","Average recall (py): 49.26%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 10/10\n","  20/2775 [..............................] - ETA: 12:53 - loss: 0.4059"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4059\n","Time used for epoch 10: 0 m 5 s\n","Evaluating on dev set after epoch 10/10:\n","Average F1 (py): 36.74%\n","Average precision (py): 49.51%\n","Average recall (py): 49.00%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Training finished!\n","Time used for training: 1 m 56 s\n","\n","Evaluating on test set:\n","Average F1 (py): 34.72%\n","Average precision (py): 46.45%\n","Average recall (py): 46.68%\n","Time used for evaluate on test set: 0 m 6 s\n","Model: \"model_9\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_19 (InputLayer)          [(None, None, None,  0           []                               \n","                                 300)]                                                            \n","                                                                                                  \n"," lambda_36 (Lambda)             (None, None, 300)    0           ['input_19[0][0]']               \n","                                                                                                  \n"," dropout_36 (Dropout)           (None, None, 300)    0           ['lambda_36[0][0]']              \n","                                                                                                  \n"," bidirectional_18 (Bidirectiona  (None, None, 100)   140400      ['dropout_36[0][0]']             \n"," l)                                                                                               \n","                                                                                                  \n"," bidirectional_19 (Bidirectiona  (None, None, 100)   60400       ['bidirectional_18[0][0]']       \n"," l)                                                                                               \n","                                                                                                  \n"," lambda_37 (Lambda)             (None, 100)          0           ['bidirectional_19[0][0]']       \n","                                                                                                  \n"," dropout_37 (Dropout)           (None, 100)          0           ['lambda_37[0][0]']              \n","                                                                                                  \n"," input_20 (InputLayer)          [(None, None, 4)]    0           []                               \n","                                                                                                  \n"," lambda_38 (Lambda)             (None, None, 4, 100  0           ['dropout_37[0][0]',             \n","                                )                                 'input_20[0][0]']               \n","                                                                                                  \n"," reshape_9 (Reshape)            (None, None, 400)    0           ['lambda_38[0][0]']              \n","                                                                                                  \n"," dense_27 (Dense)               (None, None, 50)     20050       ['reshape_9[0][0]']              \n","                                                                                                  \n"," dropout_38 (Dropout)           (None, None, 50)     0           ['dense_27[0][0]']               \n","                                                                                                  \n"," dense_28 (Dense)               (None, None, 50)     2550        ['dropout_38[0][0]']             \n","                                                                                                  \n"," dropout_39 (Dropout)           (None, None, 50)     0           ['dense_28[0][0]']               \n","                                                                                                  \n"," dense_29 (Dense)               (None, None, 1)      51          ['dropout_39[0][0]']             \n","                                                                                                  \n"," lambda_39 (Lambda)             (None, None)         0           ['dense_29[0][0]']               \n","                                                                                                  \n","==================================================================================================\n","Total params: 223,451\n","Trainable params: 223,451\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","\n","Starting training epoch 1/10\n","  20/2775 [..............................] - ETA: 12:30 - loss: 0.6442"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 18s 2ms/step - loss: 0.6442\n","Time used for epoch 1: 0 m 18 s\n","Evaluating on dev set after epoch 1/10:\n","Average F1 (py): 0.49%\n","Average precision (py): 31.46%\n","Average recall (py): 0.25%\n","Time used for evaluate on dev set: 0 m 5 s\n","\n","Starting training epoch 2/10\n","  20/2775 [..............................] - ETA: 15:45 - loss: 0.5824"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 7s 2ms/step - loss: 0.5824\n","Time used for epoch 2: 0 m 10 s\n","Evaluating on dev set after epoch 2/10:\n","Average F1 (py): 29.50%\n","Average precision (py): 34.60%\n","Average recall (py): 63.92%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 3/10\n","  20/2775 [..............................] - ETA: 18:45 - loss: 0.5214"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 8s 3ms/step - loss: 0.5214\n","Time used for epoch 3: 0 m 10 s\n","Evaluating on dev set after epoch 3/10:\n","Average F1 (py): 29.64%\n","Average precision (py): 34.04%\n","Average recall (py): 65.83%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 4/10\n","  20/2775 [..............................] - ETA: 15:25 - loss: 0.4740"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 7s 2ms/step - loss: 0.4740\n","Time used for epoch 4: 0 m 10 s\n","Evaluating on dev set after epoch 4/10:\n","Average F1 (py): 29.89%\n","Average precision (py): 34.29%\n","Average recall (py): 63.96%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 5/10\n","  20/2775 [..............................] - ETA: 12:39 - loss: 0.4529"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4529\n","Time used for epoch 5: 0 m 5 s\n","Evaluating on dev set after epoch 5/10:\n","Average F1 (py): 30.43%\n","Average precision (py): 34.61%\n","Average recall (py): 61.10%\n","Time used for evaluate on dev set: 0 m 4 s\n","\n","Starting training epoch 6/10\n","  20/2775 [..............................] - ETA: 13:03 - loss: 0.4332"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4332\n","Time used for epoch 6: 0 m 10 s\n","Evaluating on dev set after epoch 6/10:\n","Average F1 (py): 31.36%\n","Average precision (py): 38.20%\n","Average recall (py): 58.99%\n","Time used for evaluate on dev set: 0 m 4 s\n","\n","Starting training epoch 7/10\n","  20/2775 [..............................] - ETA: 14:09 - loss: 0.4175"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4175\n","Time used for epoch 7: 0 m 10 s\n","Evaluating on dev set after epoch 7/10:\n","Average F1 (py): 34.50%\n","Average precision (py): 44.92%\n","Average recall (py): 52.53%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 8/10\n","  20/2775 [..............................] - ETA: 16:41 - loss: 0.4088"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 7s 3ms/step - loss: 0.4088\n","Time used for epoch 8: 0 m 7 s\n","Evaluating on dev set after epoch 8/10:\n","Average F1 (py): 33.55%\n","Average precision (py): 42.38%\n","Average recall (py): 53.26%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 9/10\n","  20/2775 [..............................] - ETA: 14:05 - loss: 0.4148"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 6s 2ms/step - loss: 0.4148\n","Time used for epoch 9: 0 m 10 s\n","Evaluating on dev set after epoch 9/10:\n","Average F1 (py): 36.27%\n","Average precision (py): 47.34%\n","Average recall (py): 50.59%\n","Time used for evaluate on dev set: 0 m 2 s\n","\n","Starting training epoch 10/10\n","  20/2775 [..............................] - ETA: 12:22 - loss: 0.3994"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2775 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2775/2775 [==============================] - 5s 2ms/step - loss: 0.3994\n","Time used for epoch 10: 0 m 5 s\n","Evaluating on dev set after epoch 10/10:\n","Average F1 (py): 36.52%\n","Average precision (py): 48.80%\n","Average recall (py): 50.02%\n","Time used for evaluate on dev set: 0 m 4 s\n","\n","Training finished!\n","Time used for training: 2 m 12 s\n","\n","Evaluating on test set:\n","Average F1 (py): 34.40%\n","Average precision (py): 46.26%\n","Average recall (py): 47.89%\n","Time used for evaluate on test set: 0 m 5 s\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","pd.DataFrame(results).T"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"Dv_QT7QldJTD","executionInfo":{"status":"ok","timestamp":1682162237907,"user_tz":-60,"elapsed":31,"user":{"displayName":"Lydia Franklin","userId":"02300291642349467188"}},"outputId":"c45b3a4f-a63c-41e9-f23b-e1b60a8f800b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                    0           1           2           3           4  \\\n","MAX_ANT    200.000000  200.000000  200.000000  250.000000  250.000000   \n","NEG_RATIO    1.000000    2.000000    3.000000    1.000000    2.000000   \n","precision    0.355722    0.493350    0.445585    0.387425    0.470066   \n","recall       0.561894    0.461719    0.478289    0.524332    0.453837   \n","f1           0.300808    0.358599    0.342587    0.311716    0.355155   \n","\n","                    5           6           7           8  \n","MAX_ANT    250.000000  300.000000  300.000000  300.000000  \n","NEG_RATIO    3.000000    1.000000    2.000000    3.000000  \n","precision    0.475547    0.350052    0.464494    0.462602  \n","recall       0.468117    0.572513    0.466757    0.478937  \n","f1           0.349330    0.294055    0.347228    0.343982  "],"text/html":["\n","  <div id=\"df-146c117e-6035-47c5-a51f-d417d692d072\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>MAX_ANT</th>\n","      <td>200.000000</td>\n","      <td>200.000000</td>\n","      <td>200.000000</td>\n","      <td>250.000000</td>\n","      <td>250.000000</td>\n","      <td>250.000000</td>\n","      <td>300.000000</td>\n","      <td>300.000000</td>\n","      <td>300.000000</td>\n","    </tr>\n","    <tr>\n","      <th>NEG_RATIO</th>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>3.000000</td>\n","    </tr>\n","    <tr>\n","      <th>precision</th>\n","      <td>0.355722</td>\n","      <td>0.493350</td>\n","      <td>0.445585</td>\n","      <td>0.387425</td>\n","      <td>0.470066</td>\n","      <td>0.475547</td>\n","      <td>0.350052</td>\n","      <td>0.464494</td>\n","      <td>0.462602</td>\n","    </tr>\n","    <tr>\n","      <th>recall</th>\n","      <td>0.561894</td>\n","      <td>0.461719</td>\n","      <td>0.478289</td>\n","      <td>0.524332</td>\n","      <td>0.453837</td>\n","      <td>0.468117</td>\n","      <td>0.572513</td>\n","      <td>0.466757</td>\n","      <td>0.478937</td>\n","    </tr>\n","    <tr>\n","      <th>f1</th>\n","      <td>0.300808</td>\n","      <td>0.358599</td>\n","      <td>0.342587</td>\n","      <td>0.311716</td>\n","      <td>0.355155</td>\n","      <td>0.349330</td>\n","      <td>0.294055</td>\n","      <td>0.347228</td>\n","      <td>0.343982</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-146c117e-6035-47c5-a51f-d417d692d072')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-146c117e-6035-47c5-a51f-d417d692d072 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-146c117e-6035-47c5-a51f-d417d692d072');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":32}]}]}