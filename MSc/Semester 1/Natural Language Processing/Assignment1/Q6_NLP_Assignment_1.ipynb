{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "37a6e1a3-dfe4-4a7a-bdaa-141b13b699f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6807dbf9-69dc-4f98-846f-64e142b7a828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e9f676be-b58a-49ac-b8a5-a4ada81443ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv                               # csv reader\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support # to report on precision and recall\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "becd2569-addc-4a5c-8dbb-46a6d0b7583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StopWordsFromFile(filename):\n",
    "    stop_words = []\n",
    "    with open(filename) as file:\n",
    "        for i in csv.reader(file):\n",
    "            stop_words.append(i[0].lower())\n",
    "    return stop_words\n",
    "\n",
    "def StopWordRemoval(text, lexicon):\n",
    "    text = text\n",
    "    for i in lexicon:\n",
    "        while i in text:\n",
    "            text.remove(i)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "15d1009d-b90f-4a2b-a09d-3a3446c4da98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FamousPeopleFromFile(filename):\n",
    "    famous_people=[]\n",
    "    with open(filename) as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        for i in reader:\n",
    "            famous_people.append(i[0].lower())\n",
    "    return famous_people\n",
    "\n",
    "def FamousPeopleTransform(text,lexicon):\n",
    "    famous_matches = []\n",
    "    text = text\n",
    "    for i in lexicon:\n",
    "        if i in text:\n",
    "            text = re.sub(f\"(^|\\W){i}\", f\" |{len(famous_matches)} \", text)\n",
    "            famous_matches.append(i)\n",
    "    return [text, famous_matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "704ef8dc-54b8-4f5c-9c3a-de8b27b7e3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CaseFold(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0ed69506-2c62-4970-85a3-db0719be7962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nGram(text,n=[1]):\n",
    "    n = [1] + n\n",
    "    text = text\n",
    "    ngrams = []\n",
    "\n",
    "    n.sort()\n",
    "    for i in range(len(n)):\n",
    "        start = []\n",
    "        end = []\n",
    "        if n[i] == 1:\n",
    "            continue\n",
    "        for v in range(n[i]-n[i-1]):\n",
    "            start.append(\"<s>\")\n",
    "            end.append(\"</s>\")\n",
    "        # start = [\"<s>\" for v in range(i-1-count)]\n",
    "        # end = [\"</s>\" for v in range(i-1-count)]\n",
    "        text = start + text + end\n",
    "        for j in range(len(text)-n[i]+1):\n",
    "            ngrams.append(\" \".join(text[j:j+n[i]]))\n",
    "    return text+ngrams  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d0ef224c-8510-4934-b885-c545ecd3f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NegationWordsFromFile(filename):\n",
    "    negation_words = []\n",
    "    with open(filename) as file:\n",
    "        for i in csv.reader(file):\n",
    "            negation_words.append(i[0].lower())\n",
    "    return negation_words\n",
    "\n",
    "def Negate(text, lexicon):\n",
    "    text = text\n",
    "    negation_words = lexicon\n",
    "    for i in negation_words:\n",
    "        if i in text:\n",
    "            matches=[]\n",
    "            for k in range(len(text)):\n",
    "                if text[k] == i:\n",
    "                    matches.append(k)\n",
    "            for m in matches:\n",
    "                for j in range(m+1, len(text)):\n",
    "                    if (text[j]==\"not\" or \"|\" in text[j] ):\n",
    "                        continue\n",
    "                    text[j] = \"not_\" + text[j]\n",
    "                    last = text[j][-1]\n",
    "                    if (text[j][:8]==\"not_not_\"):\n",
    "                        text[j] = text[j][8:]\n",
    "                    if (text[j][-1]==\".\" or text[j][-1]==\"!\" or text[j][-1]==\"?\"):\n",
    "                        break\n",
    "        if text[-1] == \"not_\" or text[-1] == \"\":\n",
    "            text.pop()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "597258fb-b203-46de-b80f-e068db0bd5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = StopWordsFromFile(\"stop_words.csv\")\n",
    "famous_people = FamousPeopleFromFile(\"famous_people.csv\")\n",
    "negation_words = NegationWordsFromFile(\"negation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3eda6d9f-e84a-411f-b7a7-204b7c839fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
    "    with open(path,encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for line in reader:\n",
    "            if line[0] == \"Id\":  # skip header\n",
    "                continue\n",
    "            (label, data) = parse_data_line(line)\n",
    "            raw_data.append((data, label))\n",
    "\n",
    "def split_and_preprocess_data(percentage,Case_Folding=True,Punctuation=True,Stop_Word_Removal=False,Famous_People=False,nGramList=[1],Negation_Words=False,\n",
    "                              Average_Word_Length=False,Types_Per_Tokens=False,Sentiment=False, Mutual_Information=\"all\",\n",
    "                             s1=False,s2=False,s3=False,s4=False,s5=False,s6=False,s7=False,s8=False,s9=False,s10=False):\n",
    "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
    "    and performs the preprocessing.\"\"\"\n",
    "    num_samples = len(raw_data)\n",
    "    num_training_samples = int((percentage * num_samples))\n",
    "    for (data, label) in raw_data[:num_training_samples]:\n",
    "        train_data.append((to_feature_vector(pre_process(data[0],Case_Folding=Case_Folding, Punctuation=Punctuation, Stop_Word_Removal=Stop_Word_Removal,Famous_People=Famous_People, nGramList=nGramList,\n",
    "                                                         Negation_Words=Negation_Words), data[1:],\n",
    "                                             Average_Word_Length=Average_Word_Length,Types_Per_Tokens=Types_Per_Tokens,Sentiment=Sentiment,\n",
    "                                             Mutual_Information=Mutual_Information,s1=s1,s2=s2,s3=s3,s4=s4,s5=s5,s6=s6,s7=s7,s8=s8,s9=s9,s10=s10),label))\n",
    "    for (data,label) in raw_data[num_training_samples:]:\n",
    "        test_data.append((to_feature_vector(pre_process(data[0],Case_Folding=Case_Folding, Punctuation=Punctuation, Stop_Word_Removal=Stop_Word_Removal,Famous_People=Famous_People, nGramList=nGramList,\n",
    "                                                        Negation_Words=Negation_Words), data[1:],\n",
    "                                             Average_Word_Length=Average_Word_Length,Types_Per_Tokens=Types_Per_Tokens,Sentiment=Sentiment,\n",
    "                                             Mutual_Information=Mutual_Information,s1=s1,s2=s2,s3=s3,s4=s4,s5=s5,s6=s6,s7=s7,s8=s8,s9=s9,s10=s10),label))\n",
    "        \n",
    "## pre_process(text,Case_Folding=True,Punctuation=True, Stop_Word_Removal=False,Famous_People=False,nGramList=[1],Negation_Words=False):\n",
    "## to_feature_vector(tokens, Average_Word_Length=False, Types_Per_Tokens=False,Sentiment=False,Mutual_Information=False):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9bce9d0b-3e8b-4152-9a99-460366c9ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(label):\n",
    "    \"\"\"Converts the multiple classes into two,\n",
    "    making it a binary distinction between fake news and real.\"\"\"\n",
    "    #return label\n",
    "    # Converting the multiclass labels to binary label\n",
    "    labels_map = {\n",
    "        'true': 'REAL',\n",
    "        'mostly-true': 'REAL',\n",
    "        'half-true': 'REAL',\n",
    "        'false': 'FAKE',\n",
    "        'barely-true': 'FAKE',\n",
    "        'pants-fire': 'FAKE'\n",
    "    }\n",
    "    return labels_map[label]\n",
    "\n",
    "\n",
    "def parse_data_line(data_line):\n",
    "    # Should return a tuple of the label as just FAKE or REAL and the statement\n",
    "    # e.g. (label, statement)\n",
    "    # data = [conver_label(data_line[1])]\n",
    "    return (convert_label(data_line[1]),data_line[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7299bec7-c2d8-4cb3-b7b6-cb2933843fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a string of one statement\n",
    "def pre_process(text,Case_Folding=False,Punctuation=False, Stop_Word_Removal=False,Famous_People=False,nGramList=[1],Negation_Words=False):\n",
    "    ## Using famous_people, stop_words, negation_words defined above\n",
    "    text = text\n",
    "    # Should return a list of tokens\n",
    "    # DESCRIBE YOUR METHOD IN WORDS\n",
    "    ## Case Folding\n",
    "    if Case_Folding==True:\n",
    "        text = CaseFold(text)\n",
    "    ## Famous People Matching\n",
    "    if Famous_People==True:\n",
    "        text,famous_matches = FamousPeopleTransform(text,famous_people)\n",
    "    ## RegExp Pattern Match\n",
    "    if Punctuation ==True:\n",
    "        pattern = \"[^a-zA-Z0-9?!\\'\\.\\|]+\"\n",
    "    else:\n",
    "        pattern=\"\\W\"\n",
    "    text = re.split(pattern, text)\n",
    "    ## Stop Words\n",
    "    if Stop_Word_Removal == True:\n",
    "        text = StopWordRemoval(text, stop_words)\n",
    "    ## Negation Words\n",
    "    if Negation_Words == True:\n",
    "        text = Negate(text, negation_words)\n",
    "    ## Keep Punctuation\n",
    "    text = \" \".join(text)\n",
    "    replace_pattern = \"([\\.\\?\\!])\"\n",
    "    for match in re.finditer(replace_pattern, text):\n",
    "        text = text.replace(match.group(), f\" {match.group()} \")\n",
    "    text = text.split(\" \")\n",
    "    ## Famous Again\n",
    "    if Famous_People==True and famous_matches != None:\n",
    "        for i in range(len(text)):\n",
    "            if len(text[i])>1 and text[i][0] ==\"|\":\n",
    "                text[i] = famous_matches[int(text[i][1])]\n",
    "    ##\n",
    "    while \"\" in text:\n",
    "        text.remove(\"\")\n",
    "    while \"not_\" in text:\n",
    "        text.remove(\"not_\")   \n",
    "    ## n-Gram\n",
    "    text = nGram(text, nGramList)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "22408027-bbf6-4cfe-bcd6-e55718093edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AverageWordLength(tokens):\n",
    "    smn = 0\n",
    "    for i in tokens:\n",
    "        smn+= len(i)\n",
    "    return smn/len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9688364a-27ee-4649-94f6-388c6d16e340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Unique_Word_Per_Total_Words(tokens):\n",
    "    unique = len(set(tokens))\n",
    "    total_words = len(tokens)\n",
    "    return unique/total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "50ebfa45-fcba-445e-b8dd-05e103fc6e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SentimentLexiconFromFile(filename):\n",
    "    positive_sentiment = []\n",
    "    negative_sentiment = []\n",
    "    with open(filename) as file:\n",
    "        for i in csv.reader(file):\n",
    "            if i[0] == \"positive\":\n",
    "                positive_sentiment.append(i[1].lower())\n",
    "            elif i[0] == \"negative\":\n",
    "                negative_sentiment.append(i[1].lower())\n",
    "    return [negative_sentiment, positive_sentiment]\n",
    "\n",
    "def getSentiment(tokens, negative_lexicon,positive_lexicon):\n",
    "    sentiment = {\"Positive Sentiment\":0, \"Negative Sentiment\":0}\n",
    "    for token in tokens:\n",
    "        if token in negative_lexicon:\n",
    "            sentiment[\"Negative Sentiment\"]+=1\n",
    "        elif token in positive_lexicon:\n",
    "            sentiment[\"Positive Sentiment\"]+=1\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7276b535-5824-4a04-9771-ba0f18221042",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_sentiment,positive_sentiment = SentimentLexiconFromFile(\"sentiment_lexicon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0f394fdf-89cb-4308-81a7-7a3cbce6bf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6236\n",
      "8878\n",
      "13962\n"
     ]
    }
   ],
   "source": [
    "## Do it again but now with feature selection\n",
    "\n",
    "def MutualInformationFeatures(filename):\n",
    "    features = []\n",
    "    with open(filename) as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        for i in reader:\n",
    "            features.append(i[0])\n",
    "    return features\n",
    "\n",
    "MI_FAKE = MutualInformationFeatures(\"Q5_pointwise_mutual_information_FAKE.csv\")\n",
    "MI_REAL = MutualInformationFeatures(\"Q5_pointwise_mutual_information_REAL.csv\")\n",
    "MI_Features = list(set(MI_FAKE + MI_REAL))\n",
    "print(len(MI_FAKE))\n",
    "print(len(MI_REAL))\n",
    "print(len(MI_Features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d3b9c14e-a72b-4a07-9380-159c71e202fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_feature_dict = {} # A global dictionary of features\n",
    "\n",
    "def to_feature_vector(tokens,rest, Average_Word_Length=False, Types_Per_Tokens=False,Sentiment=False,Mutual_Information=\"all\",\n",
    "                      s1=False,s2=False,s3=False,s4=False,s5=False,s6=False,s7=False,s8=False,s9=False,s10=False,):\n",
    "    # Should return a dictionary containing features as keys, and weights as values\n",
    "    # DESCRIBE YOUR METHOD IN WORDS\n",
    "    features_dict = {}\n",
    "    \n",
    "    if s1==True:\n",
    "        features_dict[\"s1\"] = rest[0]\n",
    "    if s2==True:\n",
    "        features_dict[\"s2\"] = rest[1]\n",
    "    if s3==True:\n",
    "        features_dict[\"s3\"] = rest[2]\n",
    "    if s4==True:\n",
    "        features_dict[\"s4\"] = rest[3]\n",
    "    if s5==True:\n",
    "        features_dict[\"s5\"] = rest[4]\n",
    "    if s6==True:\n",
    "        features_dict[\"s6\"] = rest[5]\n",
    "    if s7==True:\n",
    "        features_dict[\"s7\"] = rest[6]\n",
    "    if s8==True:\n",
    "        features_dict[\"s8\"] = rest[7]\n",
    "    if s9==True:\n",
    "        features_dict[\"s9\"] = rest[8]\n",
    "    if s10==True:\n",
    "        features_dict[\"s10\"] = rest[9]\n",
    "    ## Average word length\n",
    "    if Average_Word_Length == True:\n",
    "        features_dict[\"Average Word Length\"] = AverageWordLength(tokens)\n",
    "    ## Unique_Words/Total_Words\n",
    "    if Types_Per_Tokens==True:\n",
    "        features_dict[\"Unique_Words/Total_Words\"] = Unique_Word_Per_Total_Words(tokens)\n",
    "    ## Sentiment Lexicon\n",
    "    if Sentiment == True:\n",
    "        features_dict.update(getSentiment(tokens, negative_sentiment,positive_sentiment))\n",
    "    ## Mutual_Information Maker\n",
    "    if Mutual_Information != \"all\":\n",
    "        MI_data = MI_Features[:Mutual_Information]\n",
    "    for token in tokens:\n",
    "        if Mutual_Information != \"all\":\n",
    "            \n",
    "            if not(token in MI_data):\n",
    "                continue\n",
    "        features_dict.setdefault(token, 0)\n",
    "        global_feature_dict.setdefault(token,0)\n",
    "        features_dict[token] += 1\n",
    "        global_feature_dict[token] += 1\n",
    "    return features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3f73a41f-83db-424d-bb49-3c09b4464462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING AND VALIDATING OUR CLASSIFIER\n",
    "\n",
    "\n",
    "def train_classifier(data,SVC_HP={}):\n",
    "    pipeline =  Pipeline([('svc', LinearSVC(**SVC_HP))])\n",
    "    return SklearnClassifier(pipeline).train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4dba5500-550f-4924-b1c2-096af217bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
    "\n",
    "def predict_labels(samples, classifier):\n",
    "    \"\"\"Assuming preprocessed samples, return their predicted labels from the classifier model.\"\"\"\n",
    "    return classifier.classify_many(samples)\n",
    "\n",
    "def predict_label_from_raw(sample, classifier):\n",
    "    \"\"\"Assuming raw text, return its predicted label from the classifier model.\"\"\"\n",
    "    return classifier.classify(to_feature_vector(preProcess(reviewSample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5c457bcf-2256-49b6-a0d0-1a1ac9968e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def cross_validate(dataset, folds,return_results=False,print_results=True, pointwiseMI=False,SVC_HP={}):\n",
    "    results = []\n",
    "    ## \n",
    "    fp = []\n",
    "    fp_dict = {}\n",
    "    fn = []\n",
    "    fn_dict = {}\n",
    "    tp = []\n",
    "    tp_dict = {}\n",
    "    tn = []\n",
    "    tn_dict = {}\n",
    "    \n",
    "    if pointwiseMI ==True:\n",
    "        smoothing_factor = 0\n",
    "        entropy_c = 0\n",
    "        features_with_count = {}\n",
    "        features_real = {}\n",
    "        features_fake = {}\n",
    "        information_gain = {}\n",
    "        mutual_information = {}\n",
    "    ## \n",
    "    ##\n",
    "    cv_results = {\n",
    "               \"FAKE\":{\"precision\":0, \"recall\":0, \"f1-score\":0},\n",
    "               \"REAL\":{\"precision\":0, \"recall\":0, \"f1-score\":0},\n",
    "               \"accuracy\":0,\n",
    "               \"macro avg\":{\"precision\":0, \"recall\":0, \"f1-score\":0},\n",
    "               \"weighted avg\":{\"precision\":0, \"recall\":0, \"f1-score\":0}\n",
    "              }\n",
    "    \n",
    "    results_headers = list(cv_results.keys())\n",
    "    results_sub_headers = list(cv_results[\"FAKE\"].keys())\n",
    "    ##\n",
    "    \n",
    "    fold_size = int(len(dataset)/folds) + 1 \n",
    "    for i in range(0,len(dataset),int(fold_size)):\n",
    "        # insert code here that trains and tests on the 10 folds of data in the dataset\n",
    "        if print_results ==True:\n",
    "            print(\"Fold start on items %d - %d\" % (i, i+fold_size))\n",
    "        # FILL IN THE METHOD HERE\n",
    "        ##\n",
    "        test = dataset[i:i+fold_size]\n",
    "        test_x = []\n",
    "        test_y = []\n",
    "        for data in test:\n",
    "            test_x.append(data[0])\n",
    "            test_y.append(data[1])\n",
    "        \n",
    "        train = dataset[0:i]\n",
    "        train.extend(dataset[i+fold_size:])\n",
    "        model = train_classifier(train,SVC_HP)\n",
    "        predicted = predict_labels(test_x, model)\n",
    "        report = classification_report(test_y, predicted, output_dict=True)\n",
    "        \n",
    "        ##\n",
    "        ##\n",
    "        \n",
    "        if i == 0:         \n",
    "            if pointwiseMI == True:\n",
    "                ## Counts\n",
    "                real_prob = test_y.count(\"REAL\")/len(test_y)\n",
    "                fake_prob = test_y.count(\"FAKE\")/len(test_y)\n",
    "\n",
    "                for value in range(len(test_y)):\n",
    "                    for k in list(test_x[value].keys()):\n",
    "                        features_with_count.setdefault(k,smoothing_factor)\n",
    "                        features_real.setdefault(k,smoothing_factor)\n",
    "                        features_fake.setdefault(k,smoothing_factor)\n",
    "                        features_with_count[k] += 1\n",
    "                        if test_y[value] == \"REAL\":\n",
    "                            features_real[k] += 1\n",
    "                        elif test_y[value] == \"FAKE\":\n",
    "                            features_fake[k] += 1\n",
    "\n",
    "                feature_count_classes = sum(features_with_count.values())\n",
    "                feature_count_real = sum(features_real.values())\n",
    "                feature_count_fake = sum(features_fake.values())\n",
    "\n",
    "                ##\n",
    "                ## Mutual Information\n",
    "\n",
    "                # These dictionaries contain the mutual information for features that occur in that class. This means that I don't have infinities.\n",
    "                # These infinities arise when when we do MLE and the probability in Pointwise mutual information in the numerator in the log is 0.\n",
    "                # This means that feature hasn't occured in that class and thus it is a good discriminator of between the classes. So these features are the best.\n",
    "                # But using the mutual information results directly with infinities isn't that useful. It doesn't tell me the best features for that particular class.\n",
    "                # So I will print to mr, mf, and mutual_information.\n",
    "                # Most likely, the best features to keep are the ones that only occur in REAL or FAKE but not both.\n",
    "\n",
    "                mr = {}\n",
    "                mf = {}\n",
    "                mr_removed = {}\n",
    "                mf_removed = {}\n",
    "\n",
    "                for feature in list(features_with_count.keys()):\n",
    "                    if features_real[feature]>0:\n",
    "                        mr[feature] = np.log2((features_real[feature]/feature_count_real)/((features_with_count[feature]/feature_count_classes)*(real_prob)))\n",
    "                    if features_fake[feature]>0:\n",
    "                        mf[feature] = np.log2((features_fake[feature]/feature_count_fake)/((features_with_count[feature]/feature_count_classes)*(fake_prob)))\n",
    "                    mutual_information.setdefault(feature,0)\n",
    "                    mutual_information[feature] = fake_prob*(mf[feature] if feature in mf else -np.inf) + real_prob*(mr[feature] if feature in mr else -np.inf)\n",
    "\n",
    "                with open(\"Q6_pointwise_mutual_information_FAKE.csv\", \"w\") as file:\n",
    "                    header = [\"Feature\", \"Mutual Information\"]\n",
    "                    writer = csv.DictWriter(file, fieldnames=header)\n",
    "                    writer.writeheader()\n",
    "                    mf_sorted = {k: v for k, v in sorted(mf.items(), key=lambda item: -item[1])}\n",
    "                    for feature,ig in mf_sorted.items():\n",
    "                        writer.writerow({header[0]:feature, header[1]: ig})\n",
    "\n",
    "                with open(\"Q6_pointwise_mutual_information_REAL.csv\", \"w\") as file:\n",
    "                    header = [\"Feature\", \"Pointwise Mutual Information\"]\n",
    "                    writer = csv.DictWriter(file, fieldnames=header)\n",
    "                    writer.writeheader()\n",
    "                    mr_sorted = {k: v for k, v in sorted(mr.items(), key=lambda item: -item[1])}\n",
    "                    for feature,ig in mr_sorted.items():\n",
    "                        writer.writerow({header[0]:feature, header[1]: ig})\n",
    "\n",
    "                with open(\"Q6_average_pointwise_mutual_information.csv\", \"w\") as file:\n",
    "                    header = [\"Feature\", \"Average Pointwise Mutual Information\"]\n",
    "                    writer = csv.DictWriter(file, fieldnames=header)\n",
    "                    writer.writeheader()\n",
    "                    mutual_information_sorted = {k: v for k, v in sorted(mutual_information.items(), key=lambda item: -item[1])}\n",
    "                    for feature,ig in mutual_information_sorted.items():\n",
    "                        writer.writerow({header[0]:feature, header[1]: ig})\n",
    "    \n",
    "        \n",
    "        ##\n",
    "        ## Appending the results for all\n",
    "        results.append(report)\n",
    "        \n",
    "        for header in results_headers:\n",
    "            if header == \"accuracy\":\n",
    "                cv_results[header] += report[\"accuracy\"]/folds\n",
    "                continue\n",
    "            for sub in results_sub_headers:\n",
    "                cv_results[header][sub] += report[header][sub]/folds\n",
    "    if print_results==True:\n",
    "        for header in results_headers:\n",
    "            if header == \"accuracy\":\n",
    "                print(f\"## {header} ## {cv_results[header]}\")\n",
    "                continue\n",
    "            print(f\"## {header} ##\")\n",
    "            for sub in results_sub_headers:\n",
    "                print(f\"{sub} : {cv_results[header][sub]}\")\n",
    "        ##\n",
    "    return cv_results if return_results==True else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "312f98fa-69be-4332-a2e0-c708642b4182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "Features = {\"Case_Folding\":True, \"Punctuation\":False,\"Stop_Word_Removal\":False,\n",
    "            \"nGramList\":[5], \"Negation_Words\":False, \"Average_Word_Length\":True,\n",
    "            \"Types_Per_Tokens\":True,\"Sentiment\":True,\"Mutual_Information\":\"all\"}\n",
    "HP = {\"loss\":\"hinge\",\"C\":0.2}\n",
    "\n",
    "testing = [{\"s1\":True},{\"s2\":True},{\"s3\":True},{\"s4\":True},{\"s5\":True},{\"s6\":True},\n",
    "          {\"s7\":True},{\"s8\":True},{\"s9\":True},{\"s10\":True}]\n",
    "\n",
    "results_data =[]\n",
    "\n",
    "raw_data = []\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for i in testing:\n",
    "    print(len(results_data))\n",
    "    \n",
    "    n_features = Features.copy()\n",
    "    n_features.update(i)\n",
    "    \n",
    "    raw_data = []\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "\n",
    "    \n",
    "    data_file_path = 'fake_news.tsv'\n",
    "\n",
    "    load_data(data_file_path) \n",
    "    split_and_preprocess_data(0.8, **n_features)\n",
    "    results_data.append({\"parameter\":i,\"score\":cross_validate(train_data, 10, print_results=False,return_results=True, pointwiseMI=True, SVC_HP=HP)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "25b340e7-4ca9-43ee-bfda-009c56ade4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Q6_New_Feature_Analysis.csv\",\"w\") as file:\n",
    "    header = [\"Feature\", \"FAKE precision\",\"FAKE recall\",\"FAKE f1-score\",\n",
    "              \"REAL precision\", \"REAL recall\", \"REAL f1-score\",\n",
    "              \"accuracy\",\"macro avg precision\", \"macro avg recall\", \"macro avg f1-score\",\n",
    "              \"weighted avg precision\", \"weighted avg recall\", \"weighted avg f1-score\"]\n",
    "    writer = csv.DictWriter(file, fieldnames=header)\n",
    "    writer.writeheader()\n",
    "    for i in results_data:\n",
    "        t = {\"Feature\":i[\"parameter\"], \n",
    "             \"FAKE precision\":i[\"score\"][\"FAKE\"][\"precision\"],\n",
    "             \"FAKE recall\":i[\"score\"][\"FAKE\"][\"recall\"],\n",
    "             \"FAKE f1-score\":i[\"score\"][\"FAKE\"][\"f1-score\"],\n",
    "             \"REAL precision\":i[\"score\"][\"REAL\"][\"precision\"],\n",
    "             \"REAL recall\":i[\"score\"][\"REAL\"][\"recall\"],\n",
    "             \"REAL f1-score\":i[\"score\"][\"REAL\"][\"f1-score\"],\n",
    "             \"accuracy\":i[\"score\"][\"accuracy\"],\n",
    "             \"macro avg precision\":i[\"score\"][\"macro avg\"][\"precision\"],\n",
    "             \"macro avg recall\":i[\"score\"][\"macro avg\"][\"recall\"],\n",
    "             \"macro avg f1-score\":i[\"score\"][\"macro avg\"][\"f1-score\"],\n",
    "             \"weighted avg precision\":i[\"score\"][\"weighted avg\"][\"precision\"],\n",
    "             \"weighted avg recall\":i[\"score\"][\"weighted avg\"][\"recall\"],\n",
    "             \"weighted avg f1-score\":i[\"score\"][\"weighted avg\"][\"f1-score\"]\n",
    "            }\n",
    "        writer.writerow(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "47a5bfdb-d50a-49f0-81a0-a328d8d24d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold start on items 0 - 820\n",
      "Fold start on items 820 - 1640\n",
      "Fold start on items 1640 - 2460\n",
      "Fold start on items 2460 - 3280\n",
      "Fold start on items 3280 - 4100\n",
      "Fold start on items 4100 - 4920\n",
      "Fold start on items 4920 - 5740\n",
      "Fold start on items 5740 - 6560\n",
      "Fold start on items 6560 - 7380\n",
      "Fold start on items 7380 - 8200\n",
      "## FAKE ##\n",
      "precision : 0.6756932927490217\n",
      "recall : 0.6466828827641089\n",
      "f1-score : 0.6605444127663895\n",
      "## REAL ##\n",
      "precision : 0.736498264852891\n",
      "recall : 0.7610506785707933\n",
      "f1-score : 0.7483504774939539\n",
      "## accuracy ## 0.7112207136849693\n",
      "## macro avg ##\n",
      "precision : 0.7060957788009563\n",
      "recall : 0.7038667806674511\n",
      "f1-score : 0.7044474451301718\n",
      "## weighted avg ##\n",
      "precision : 0.7106892477205656\n",
      "recall : 0.7112207136849693\n",
      "f1-score : 0.7104308831853742\n"
     ]
    }
   ],
   "source": [
    "Features = {\"Case_Folding\":True, \"Punctuation\":False,\"Stop_Word_Removal\":False,\n",
    "            \"nGramList\":[5], \"Negation_Words\":False, \"Average_Word_Length\":True,\n",
    "            \"Types_Per_Tokens\":True,\"Sentiment\":True,\"Mutual_Information\":\"all\",\n",
    "            \"s1\":True,\"s2\":True,\"s3\":True,\"s4\":True,\"s5\":True,\"s6\":True,\n",
    "            \"s7\":True,\"s8\":True,\"s9\":True,\"s10\":True}\n",
    "HP = {\"loss\":\"hinge\",\"C\":0.2}\n",
    "\n",
    "\n",
    "raw_data = []\n",
    "train_data = []\n",
    "test_data = []\n",
    "    \n",
    "data_file_path = 'fake_news.tsv'\n",
    "\n",
    "load_data(data_file_path) \n",
    "split_and_preprocess_data(0.8, **Features)\n",
    "cross_validate(train_data, 10, print_results=True, SVC_HP=HP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "78e0f045-4203-41a0-bb22-4528f7386ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'s1': 'bush-administration,deficit,taxes', 's2': 'dennis-kucinich', 's3': 'U.S. representative', 's4': 'Ohio', 's5': 'democrat', 's6': '1', 's7': '3', 's8': '4', 's9': '6', 's10': '0', 'Average Word Length': 13.210526315789474, 'Unique_Words/Total_Words': 0.8157894736842105, 'Positive Sentiment': 1, 'Negative Sentiment': 0, '<s>': 4, 'the': 2, 'bush': 1, 'tax': 1, 'cuts': 1, 'helped': 1, 'to': 1, 'create': 1, 'a': 1, 'substantial': 1, 'part': 1, 'of': 1, 'deficit': 1, '</s>': 4, '<s> <s> <s> <s> the': 1, '<s> <s> <s> the bush': 1, '<s> <s> the bush tax': 1, '<s> the bush tax cuts': 1, 'the bush tax cuts helped': 1, 'bush tax cuts helped to': 1, 'tax cuts helped to create': 1, 'cuts helped to create a': 1, 'helped to create a substantial': 1, 'to create a substantial part': 1, 'create a substantial part of': 1, 'a substantial part of the': 1, 'substantial part of the deficit': 1, 'part of the deficit </s>': 1, 'of the deficit </s> </s>': 1, 'the deficit </s> </s> </s>': 1, 'deficit </s> </s> </s> </s>': 1}, 'REAL')\n",
      "Done training!\n",
      "\n",
      "\n",
      "\n",
      "Accuracy:  0.6974133723767691\n",
      "\n",
      "\n",
      "Macro:\n",
      "Precision: 0.695275\n",
      "Recall: 0.690138\n",
      "F Score:0.691185\n",
      "\n",
      "\n",
      "Weighted:\n",
      "Precision: 0.696369\n",
      "Recall: 0.697413\n",
      "F Score:0.695401\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Finally, check the accuracy of your classifier by training on all the traning data\n",
    "# and testing on the test set\n",
    "# Will only work once all functions are complete\n",
    "functions_complete = True  # set to True once you're happy with your methods for cross val\n",
    "if functions_complete:\n",
    "    print(test_data[0])   # have a look at the first test data instance\n",
    "    classifier = train_classifier(train_data,SVC_HP=HP)  # train the classifier\n",
    "    test_true = [t[1] for t in test_data]   # get the ground-truth labels from the data\n",
    "    test_pred = predict_labels([x[0] for x in test_data], classifier)  # classify the test data to get predicted labels\n",
    "    print(\"Done training!\")\n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"Accuracy: \",accuracy_score(test_true,test_pred))\n",
    "    print(\"\\n\\nMacro:\")\n",
    "    final_scores = precision_recall_fscore_support(test_true, test_pred, average='macro') # evaluate\n",
    "    print(\"Precision: %f\\nRecall: %f\\nF Score:%f\" % final_scores[:3])\n",
    "    \n",
    "    \n",
    "    final_scores = precision_recall_fscore_support(test_true, test_pred, average='weighted') # evaluate    \n",
    "\n",
    "    print(\"\\n\\nWeighted:\")\n",
    "    print(\"Precision: %f\\nRecall: %f\\nF Score:%f\" % final_scores[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eee792-33fa-459e-8cae-1b2b6d5722d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
